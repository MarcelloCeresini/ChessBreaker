{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2iWAxgCHN7z"
      },
      "outputs": [],
      "source": [
        "username = 'MarcelloCeresini'\n",
        "repository = 'ChessBreaker'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG5cfeYvHhdU",
        "outputId": "83f1d0f6-6925-4b26-a582-8485ff66edde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "Cloning into 'ChessBreaker'...\n",
            "remote: Enumerating objects: 300, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 300 (delta 70), reused 76 (delta 30), pack-reused 172\u001b[K\n",
            "Receiving objects: 100% (300/300), 4.47 MiB | 31.82 MiB/s, done.\n",
            "Resolving deltas: 100% (169/169), done.\n",
            "/content/ChessBreaker\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                  model.py                      requirements.txt\n",
            "data_processing.ipynb  notes.txt                     \u001b[01;34mresults\u001b[0m/\n",
            "elo_eval.ipynb         old_imitation_learning.ipynb  \u001b[01;34mside_stuff\u001b[0m/\n",
            "imitation_learning.py  \u001b[01;34mold_stuff\u001b[0m/                    try_a_match.ipynb\n",
            "main.ipynb             random_endgame_gen.ipynb      utils.py\n",
            "mini_resnet.png        README.md\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting anytree\n",
            "  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 530 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree) (1.15.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.8.0\n"
          ]
        }
      ],
      "source": [
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "    #%cd /content/drive/MyDrive/GitHub/\n",
        "    !git clone https://github.com/{username}/{repository}.git\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "    !pip3 install anytree\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qDwSWUnXcjn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import chess\n",
        "from anytree import Node\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from queue import Queue\n",
        "from collections import deque\n",
        "\n",
        "from numpy.random import default_rng\n",
        "rng = default_rng()\n",
        "\n",
        "import utils\n",
        "from utils import plane_dict, Config, x_y_from_position\n",
        "from model import ResNet\n",
        "\n",
        "conf = Config()\n",
        "board = chess.Board()\n",
        "\n",
        "# legal_moves = board.legal_moves\n",
        "# for move in legal_moves:\n",
        "#     print(move.uci())  \n",
        "# print(legal_moves)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv2zcMiUh9bU"
      },
      "outputs": [],
      "source": [
        "class MyNode(Node): # subclassing Node from Anytree to add some methods\n",
        "\n",
        "    def update_action_value(self, new_action_value):                                                        # used during backtracking to update action value if the simulation reached the end through that node\n",
        "        self.action_value += (new_action_value-self.action_value)/(self.visit_count+1)                      # simply the mean value, but computed iteratively\n",
        "\n",
        "    def calculate_upper_confidence_bound(self, num_total_iterations=1):                                     # Q + U --> U proportional to P/(1+N) --> parameter decides exploration vs. exploitation\n",
        "        new_UCF = self.action_value + conf.expl_param(num_total_iterations)*self.prior/(1+self.visit_count)\n",
        "        return new_UCF\n",
        "\n",
        "    def calculate_move_probability(self, num_move=1):                                           # N^(1/tau) --> tau is a temperature parameter (exploration vs. exploitation)\n",
        "        return self.visit_count**(1/conf.temp_param(num_move))\n",
        "\n",
        "\n",
        "def MTCS(model, root_node, max_depth, num_restarts):\n",
        "    '''\n",
        "        The search descends until it finds a leaf to be evalued, then restarts until it gathers a batch of evaluations, then expands all the nodes in the batch\n",
        "        If the maximum depth is reached, the algorithm then backpropagates the action value of the reached node back to the root of the tree\n",
        "        Exploration incentivised by the decrease of action value / upper confidence bound with each visit to the node\n",
        "        Exploitation incentivised by the two parameters temp_param and expl_param (respectively to choose almost surely the most probable move, and to focus more on the action value rather than the prior of the node)\n",
        "    '''\n",
        "    evaluation_counter = 0\n",
        "    INIT_ROOT = root_node\n",
        "    nodes_to_visit = Queue()\n",
        "    # number of times to explore up until max_depth\n",
        "    i = 0\n",
        "\n",
        "    leaf_node_batch = []\n",
        "    legal_moves_batch = []\n",
        "    \n",
        "    while i < num_restarts:\n",
        "        if nodes_to_visit.empty():\n",
        "            root_node = INIT_ROOT\n",
        "            i+=1\n",
        "        else:\n",
        "            root_node = nodes_to_visit.get_nowait()\n",
        "        # print(i, root_node.name, root_node.depth, root_node.visit_count)\n",
        "        \n",
        "        step_down = True\n",
        "        control_counter = 0\n",
        "        while step_down:\n",
        "            control_counter+=1\n",
        "            if control_counter > 2*max_depth: \n",
        "                print(\"stuck in loop, leaving\")\n",
        "                break # bigger margin, but if it is stuk in a loop for some reason, at least it leaves\n",
        "            \n",
        "            # assert root_node.depth >= 0 and root_node.depth <= max_depth, \"depth is wrong\"\n",
        "            if root_node.is_leaf and not root_node.is_finish_position:                                                                           # if it's leaf --> need to pass the position (planes) through the model, to get priors (action_values) and outcome (state_value)\n",
        "                step_down = False\n",
        "\n",
        "                if len(root_node.siblings) > 0:         # this part is to try and avoid batching the same node twice (so we evaluate a random sibling instead)\n",
        "                    leaf_node_list = [node.board_history for node in leaf_node_batch]\n",
        "                    if root_node.board_history in leaf_node_list:\n",
        "                        siblings_list = list(root_node.siblings)\n",
        "                        random_sibling = np.random.choice(siblings_list)\n",
        "                        while random_sibling.board_history in leaf_node_list and len(siblings_list)>1:\n",
        "                            siblings_list.remove(random_sibling) #do it with np.random in a range, and POP instead of remove\n",
        "                            random_sibling = np.random.choice(siblings_list)\n",
        "                        \n",
        "                        root_node = random_sibling\n",
        "                        \n",
        "                # important! save legal moves AFTER choosing root_node\n",
        "                legal_moves = list(root_node.board.legal_moves)\n",
        "\n",
        "                if len(legal_moves) == 0:\n",
        "                    step_down = False\n",
        "                    final_outcome = root_node.board.outcome(claim_draw=True)\n",
        "\n",
        "                    if final_outcome != None:\n",
        "                        root_node.is_finish_position = True\n",
        "                        if final_outcome.winner == None:\n",
        "                            root_node.action_value = 0\n",
        "                        else:\n",
        "                            root_node.action_value = int(final_outcome.winner)*2-1\n",
        "                    else:\n",
        "                        print(\"Something's wrong\")\n",
        "                else:\n",
        "                    leaf_node_batch.append(root_node)\n",
        "                    legal_moves_batch.append(legal_moves)\n",
        "                \n",
        "                root_node.visit_count += 1\n",
        "\n",
        "                # print(\"to be evaluated\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "\n",
        "                if len(leaf_node_batch) == conf.BATCH_DIM or root_node == INIT_ROOT:\n",
        "                    # in order to avoid creating multiple times the children of the same node, we only keep unique values\n",
        "                    if len(set(leaf_node_batch)) < conf.BATCH_DIM:\n",
        "                        leaf_node_batch, legal_moves_batch = utils.reduce_repetitions(leaf_node_batch, legal_moves_batch)                    \n",
        "                    \n",
        "                    plane_list = [root_node.planes for root_node in leaf_node_batch]\n",
        "                    # 0.0032072067260742188\n",
        "                    # 7.05718994140625e-05\n",
        "                    \n",
        "                    planes = np.stack(plane_list)\n",
        "\n",
        "                    full_moves_batch, outcome_batch = model(planes)\n",
        "                    evaluation_counter+=1\n",
        "\n",
        "                    full_moves_batch_np = full_moves_batch.numpy()\n",
        "                    # print(np.shape(full_moves_batch_np[0]))\n",
        "                    outcome_batch_np = outcome_batch.numpy()\n",
        "\n",
        "                    if np.shape(full_moves_batch_np)[0] != 1:\n",
        "                        full_moves_batch_np = np.moveaxis(full_moves_batch.numpy(), 0, 0)\n",
        "                        outcome_batch_np = np.moveaxis(outcome_batch.numpy(), 0, 0)\n",
        "                    \n",
        "                    for root_node, full_moves, outcome, legal_moves in zip(leaf_node_batch, full_moves_batch_np, outcome_batch_np, legal_moves_batch):\n",
        "                        nodes_to_visit.put_nowait(root_node)\n",
        "                        \n",
        "                        mask_idx = utils.mask_moves(legal_moves)\n",
        "                        priors = [full_moves[idx[0], idx[1], idx[2]] for idx in mask_idx]                        # boolean mask returns a tensor of only the values that were masked (as a list let's say)\n",
        "                        # 0.006434917449951172\n",
        "                        # 1.3113021850585938e-05\n",
        "                        root_node.action_value = outcome    \n",
        "                        \n",
        "                        if root_node == INIT_ROOT:  # increase exploration at the root, since if the network is not good it will not make good starting choices\n",
        "                            dir_noise = rng.dirichlet([conf.ALPHA_DIRICHLET]*len(priors))\n",
        "                            priors = (1-conf.EPS_NOISE)*priors + conf.EPS_NOISE*dir_noise\n",
        "\n",
        "                        for move, prior in zip(legal_moves, priors):                                                # creating children\n",
        "\n",
        "                            root_board_fen = root_node.board.fen()\n",
        "                            new_board = chess.Board()\n",
        "                            new_board.set_fen(root_board_fen)\n",
        "                            new_board.push(move)\n",
        "                                                        \n",
        "                            new_board_history = root_node.board_history.copy()                                      # and board history! (copy because list are pointers)\n",
        "                            new_board_history.append(new_board.fen()[:-6])\n",
        "\n",
        "                            planes = utils.update_planes(root_node.planes, new_board, new_board_history)\n",
        "                            \n",
        "                            MyNode(\n",
        "                                move.uci(), \n",
        "                                parent = root_node,                                                                 # very important to build the tree\n",
        "                                prior = prior,                                                                      # prior is the \"initial\" state_value of a node\n",
        "                                visit_count = 0,                                                                    # initialize visit_count to 0\n",
        "                                action_value = 0,\n",
        "                                is_finish_position = False,\n",
        "                                board = new_board, \n",
        "                                board_history = new_board_history,                                                  \n",
        "                                planes = planes             # update the planes --> each node stores its input planes!\n",
        "                            )\n",
        "\n",
        "                    leaf_node_batch = []\n",
        "                    legal_moves_batch = []\n",
        "\n",
        "            else: # if it does not need to be evalued because it already has children \n",
        "                if root_node.depth < max_depth and not root_node.is_finish_position:                                # if we are normally descending\n",
        "                    # print(\"choosing point\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                    children = root_node.children                                                               # get all the children (always != [])\n",
        "                    \n",
        "                    values = [child.calculate_upper_confidence_bound() for child in children]\n",
        "                    root_node = children[np.argmax(values)]\n",
        "                    root_node.visit_count += 1                                                                  # add 1 to the visit count of the chosen child\n",
        "                    # print(\"chosen node\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                else:\n",
        "                    step_down = False                                # it will leave the while, max depth is reached\n",
        "                    # print(\"final leaf\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name, root_node.calculate_upper_confidence_bound())\n",
        "                    outcome = root_node.action_value    # needed for when depth=max_depth AND NOT LEAF (that means, already visited leaf) --> don't REDO the evaluation, it would give the same result, simply copy it from before\n",
        "                    # barckpropagation of action value through the tree\n",
        "                    while root_node.depth > 0:\n",
        "                        # root node should be an already evalued leaf, at max depth (so OUTCOME has been set)\n",
        "                        # assert root_node.depth > 0 and root_node.depth <= max_depth, \"depth is wrong\"\n",
        "                        root_node = root_node.parent\n",
        "                        root_node.update_action_value(outcome)\n",
        "\n",
        "    return INIT_ROOT, evaluation_counter\n",
        "\n",
        "\n",
        "def choose_move(root_node, num_move):\n",
        "    # add dirichlet noise to the root node? (page 14, Mastering Chess and Shogi by self play... --> configuration)\n",
        "    children = root_node.children\n",
        "    assert root_node.children != [], \"No children, cannot choose move\"\n",
        "    p = [child.calculate_move_probability(num_move) for child in children] \n",
        "    p_norm = [i/sum(p) for i in p] # normalize probabilities\n",
        "\n",
        "    root_node = np.random.choice(\n",
        "        children, \n",
        "        p = p_norm  # choose the child proportionally to the number of times it has been visited (exponentiated by a temperature parameter)\n",
        "    ) \n",
        "    root_node.parent = None # To detach the subtree and restart with the next move search\n",
        "\n",
        "    return root_node\n",
        "\n",
        "\n",
        "def complete_game(model, starting_fen=None, max_depth=conf.MAX_DEPTH, num_restarts=conf.NUM_RESTARTS):\n",
        "    move_list = []\n",
        "    \n",
        "    board = chess.Board()\n",
        "    if starting_fen != None:\n",
        "        board.set_fen(starting_fen)\n",
        "    board_history = [board.fen()[:-6]]                           # we remove the \"en passant\", \"halfmove clock\" and \"fullmove number\" from the fen --> position will be identical even if those values differ\n",
        "    \n",
        "    root_node = MyNode(\n",
        "        \"Start\",                                                     # no name needed for initial position\n",
        "        board = board,\n",
        "        board_history = board_history,\n",
        "        planes = utils.update_planes(None, board, board_history),    # start from empty planes and fill them (usually you need previous planes to fill them)\n",
        "        action_value=0,\n",
        "        visit_count=0,\n",
        "        is_finish_position = False\n",
        "        )\n",
        "\n",
        "    results = []\n",
        "    match_planes = []\n",
        "    match_policy = []\n",
        "    move_counter = 0\n",
        "    # while not root_node.board.is_game_over(claim_draw=True) and root_node.board.fullmove_number <= conf.MAX_MOVE_COUNT:\n",
        "    while not root_node.board.is_game_over(claim_draw=True) and move_counter < conf.MAX_MOVE_COUNT:\n",
        "        move_counter += 1\n",
        "        tic = time()\n",
        "        root_node, eval_c = MTCS(model, root_node, max_depth = max_depth, num_restarts=num_restarts)                            # though the root node you can access all the tree\n",
        "\n",
        "        match_planes.append(root_node.planes)                                                                                   # 8x8x113\n",
        "        root_node = choose_move(root_node, num_move=move_counter)                                                                                      \n",
        "        match_policy.append(utils.mask_moves([chess.Move.from_uci(root_node.name)])[0])                                         # appends JUST AN INDEX\n",
        "\n",
        "        ###### only for debugging ######\n",
        "        move_list.append(chess.Move.from_uci(root_node.name))\n",
        "        results.append((\n",
        "            int(root_node.planes[0,0,conf.REPEATED_PLANES+conf.OLD_PLANES_TO_KEEP+1]),  # it is the fullmove number\n",
        "            root_node.visit_count,\n",
        "            eval_c,\n",
        "            time()-tic,\n",
        "            root_node.action_value))\n",
        "        \n",
        "        print(move_counter, time()-tic)\n",
        "        ################################\n",
        "\n",
        "    if move_counter >= conf.MAX_MOVE_COUNT:\n",
        "        outcome = utils.outcome(\"1/2-1/2\")\n",
        "    else:\n",
        "        outcome = utils.outcome(root_node.board.outcome(claim_draw=True).result())\n",
        "\n",
        "    # TODO: try if \"match_policy\" is a problem, because it's a list\n",
        "    # return move_list, outcome, results, match_planes, match_policy                             # only needed for the program are the match_planes (input for learning) and the outcome/match_policy (loss)\n",
        "    return match_planes, match_policy, outcome\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNRD2BohKG2g"
      },
      "outputs": [],
      "source": [
        "# model = ResNet()\n",
        "# DUMMY_INPUT = tf.stack([tf.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES])]*8, axis = 0)\n",
        "# print(tf.shape(DUMMY_INPUT))\n",
        "# fm, ac = model(DUMMY_INPUT)\n",
        "# print(\"full moves shape\", fm.shape)\n",
        "# print(\"action values shape\", ac.shape)\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pHHpicUKG2h"
      },
      "outputs": [],
      "source": [
        "# res_dict = {}\n",
        "# games = []\n",
        "# outcomes = []\n",
        "# for depth in [8, 6, 4, 2]:\n",
        "#     for n_rep in [100, 80, 60, 40, 30, 20, 10, 5]:\n",
        "#         tic = time()\n",
        "#         moves, outcome, results, _, _ = complete_game(model, max_depth=depth, num_restarts=n_rep)\n",
        "#         res_dict[(depth, n_rep, \"eval\")] = np.average([res[2] for res in results])\n",
        "#         res_dict[(depth, n_rep, \"time\")] = np.average([res[3] for res in results])\n",
        "#         games.append(moves)\n",
        "#         outcomes.append(outcome)\n",
        "#         print(depth, \"\\t\", n_rep, \"\\t\", time()-tic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vRhjzdqR-4e",
        "outputId": "8a2c0e07-4371-4528-d02d-01fe8d012679"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Total evaluations')"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# reps = [5, 10, 20, 30, 40, 60, 80, 100]\n",
        "# depths = [2, 4, 6, 8]\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "# [plt.scatter(reps, [res_dict[(depth, rep, \"eval\")] for rep in reps]) for depth in depths]\n",
        "\n",
        "# plt.legend(depths)\n",
        "# plt.title(\"Evaluations vs. repetitions\")\n",
        "# plt.xlabel(\"Repetitions\")\n",
        "# plt.ylabel(\"Total evaluations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1HAFM0ZR-4f",
        "outputId": "1a7569a8-90bb-4bc1-e0a9-7ac7cdd1fae1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean time per move')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "# [plt.scatter(reps, [res_dict[(depth, rep, \"time\")] for rep in reps]) for depth in depths]\n",
        "# # plt.scatter(reps, times)\n",
        "\n",
        "# plt.legend(depths)\n",
        "# plt.title(\"Time vs. repetitions\")\n",
        "# plt.xlabel(\"Repetitions\")\n",
        "# plt.ylabel(\"Mean time per move\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg2o4fMGR-4h"
      },
      "outputs": [],
      "source": [
        "# import json, codecs\n",
        "\n",
        "# Zl = [[res_dict[(depth, rep, \"time\")] for rep in reps] for depth in depths]\n",
        "\n",
        "# X, Y = np.meshgrid(reps, depths)\n",
        "# # Z_time = np.stack([\n",
        "# #     times\n",
        "# # ])\n",
        "\n",
        "\n",
        "# Xl = X.tolist() # nested lists with same data, indices\n",
        "# Yl = Y.tolist() # nested lists with same data, indices\n",
        "# # Zl = Z_time.tolist() # nested lists with same data, indices\n",
        "\n",
        "# file_path_X = \"data/chartX.json\" ## your path variable\n",
        "# file_path_Y = \"data/chartY.json\" ## your path variable\n",
        "# file_path_Z = \"data/chartZ.json\" ## your path variable\n",
        "\n",
        "# json.dump(Xl, codecs.open(file_path_X, 'w', encoding='utf-8'), \n",
        "#           separators=(',', ':'), \n",
        "#           sort_keys=True, \n",
        "#           indent=4) ### this saves the array in .json format\n",
        "\n",
        "# json.dump(Yl, codecs.open(file_path_Y, 'w', encoding='utf-8'), \n",
        "#           separators=(',', ':'), \n",
        "#           sort_keys=True, \n",
        "#           indent=4) ### this saves the array in .json format\n",
        "\n",
        "# json.dump(Zl, codecs.open(file_path_Z, 'w', encoding='utf-8'), \n",
        "#           separators=(',', ':'), \n",
        "#           sort_keys=True, \n",
        "#           indent=4) ### this saves the array in .json format\n",
        "\n",
        "# # fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
        "# # surf = ax.plot_surface(X, Y, Z_time, linewidth=0, antialiased=False)\n",
        "\n",
        "# # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4OzNXseR-4k"
      },
      "outputs": [],
      "source": [
        "path_fixed_model = \"models/fixed_model\"       # create a model that continually learns, and another model that is fixed and does the MCTS\n",
        "path_updating_model = \"models/updating_model\"    # every now and then update the second model to match the first one\n",
        "path_checkpoints_for_evaluation = \"model_checkpoint/step-{}\"\n",
        "dataset = tf.data.TextLineDataset(\"dataset/rand_pos_train.txt\").shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "MAX_SIZE = 70000\n",
        "NUM_PARALLEL_GAMES = 160\n",
        "NUM_TRAINING_STEPS = 100\n",
        "# using np.arrays because we add chunks of data and not one at a time (O(n) to move all data is actually O(n/m), with m chunk size)\n",
        "# and also we need to sample randomly batches of data, that for linked lists (like queue) is O(n*batch_zize), instead for arrays is O(batch_size)\n",
        "experience_buffer_planes = np.zeros((MAX_SIZE, 8, 8, 119), dtype=conf.PLANES_DTYPE_NP)  # the bigger the better, check with some experiments\n",
        "experience_buffer_moves = np.zeros((MAX_SIZE, 1), dtype=conf.PLANES_DTYPE_NP)   # the bigger the better, check with some experiments\n",
        "experience_buffer_outcome = np.zeros((MAX_SIZE, 1), dtype=conf.PLANES_DTYPE_NP) # the bigger the better, check with some experiments\n",
        "# start_learning_from = 50000 # number of MOVES\n",
        "\n",
        "# idea: start learning after 50000 samples are in the queue, and randomly select them to pass them through the network, then REMOVE them from the queue\n",
        "# IN PARALLEL, keep playing games with the fixed_model to fill up the queue --> if this step is much faster (or the opposite) --> just wait a bit for the slower one, so that the queue always stays\n",
        "# between ~50k and ~100k\n",
        "\n",
        "# ideally: infinite while loop that launches in parallel two threads/processes:\n",
        "# 1) generates self-play samples (planes, (moves, outcome)) that then get COPIED (otherwise parallelism will screw everything up) and added to the queue\n",
        "# 2) randomly selects batches of 512 samples from the buffer\n",
        "\n",
        "steps_per_update = 1000 # STEPS! so it's 1000*batch moves\n",
        "steps_per_eval = 50000\n",
        "TOTAL_STEPS = 500000 # 5 millions\n",
        "\n",
        "from multiprocessing import Process, Pool, Value\n",
        "from numpy.random import default_rng\n",
        "rng = default_rng()\n",
        "\n",
        "def play_parallel_games_apply(model, num_games, filled_up, experience_buffer_planes, experience_buffer_moves, experience_buffer_outcome):\n",
        "    tic = time()\n",
        "    tot_num_moves = 0\n",
        "\n",
        "    tot_planes = []\n",
        "    tot_moves = []\n",
        "    tot_outcome = []\n",
        "\n",
        "    starting_positions = dataset.take(num_games)\n",
        "    with Pool() as pool: # play as many games as possible in parallel, and add them to the queue\n",
        "        futures = [pool.apply_async(complete_game, [model, position]) for w, position in zip(num_games, starting_positions)]\n",
        "        for f in futures:\n",
        "            planes, moves, result = f.get()\n",
        "            num_planes = len(planes)\n",
        "            \n",
        "            to_remove = min(0, (filled_up + num_planes) - MAX_SIZE)\n",
        "            to_move = MAX_SIZE - to_remove\n",
        "            experience_buffer_planes[:to_move, ...] = experience_buffer_planes[to_remove:, ...]\n",
        "            experience_buffer_moves[:to_move, ...] = experience_buffer_moves[to_remove:, ...]\n",
        "            experience_buffer_outcome[:to_move, ...] = experience_buffer_outcome[to_remove:, ...]\n",
        "\n",
        "            experience_buffer_planes[to_move:to_move+num_planes, ...] = np.stack(planes)\n",
        "            experience_buffer_moves[to_move:to_move+num_planes, ...] = np.stack(moves)\n",
        "            experience_buffer_outcome[to_move:to_move+num_planes, ...] = np.repeat(result, num_planes)\n",
        "\n",
        "            tot_num_moves += num_planes\n",
        "            filled_up = max(filled_up+num_planes, MAX_SIZE)\n",
        "\n",
        "    print(\"games\", time()-tic)\n",
        "    return tot_num_moves, filled_up\n",
        "\n",
        "\n",
        "# def play_parallel_games_imap(model, experience_buffer, num_games):\n",
        "#     tic = time()\n",
        "#     tot_moves = 0\n",
        "#     with Pool() as pool: # play as many games as possible in parallel, and add them to the queue\n",
        "#         futures = pool.imap_unordered(eval, [model]*num_games)\n",
        "#         for f in futures:\n",
        "#             planes, moves, result = f\n",
        "#             tot_moves += (len(planes))\n",
        "#             for plane, move in zip(planes, moves):\n",
        "#                 experience_buffer.append((plane, (move, result)))\n",
        "#     print(\"games\", time()-tic)\n",
        "#     return tot_moves\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def gradient_application(x, y_policy, y_value, optimizer, metric):\n",
        "    with tf.GradientTape() as tape:\n",
        "        policy_logits, value_logits = model(x)\n",
        "        policy_loss_value = utils.loss_policy(y_policy, policy_logits)\n",
        "        value_loss_value = utils.loss_value(y_value, value_logits)\n",
        "        loss = policy_loss_value + value_loss_value + sum(model.losses) # to add regularization loss\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    metric.update_state(y_policy, policy_logits)\n",
        "\n",
        "    return policy_loss_value, value_loss_value, loss\n",
        "\n",
        "\n",
        "def train_step(model, filled_up, optimizer, loss_policy, loss_value, metric, steps):\n",
        "    tic = time()\n",
        "    total_loss = 0\n",
        "\n",
        "    sample_idxs = rng.choice(range(MAX_SIZE), size=conf.SELF_PLAY_BATCH, replace=False)\n",
        "    # create the batch and remove them from the buffer\n",
        "    planes_batch = [experience_buffer_planes[idx] for idx in sample_idxs] # you don't pop them\n",
        "    moves_batch = [experience_buffer_moves[idx] for idx in sample_idxs] # you don't pop them\n",
        "    outcome_batch = [experience_buffer_outcome[idx] for idx in sample_idxs] # you don't pop them\n",
        "        \n",
        "    policy_loss_value, value_loss_value, loss = gradient_application(planes_batch, moves_batch, outcome_batch, optimizer, metric)\n",
        "\n",
        "    if steps % steps_per_update == 0:\n",
        "        to_print = [\"step: \", steps]\n",
        "        to_print.append(\"- policy loss (instantaneous): \")\n",
        "        to_print.append(policy_loss_value)\n",
        "        to_print.append(\"- value_loss (instantaneous): \")\n",
        "        to_print.append(value_loss_value)\n",
        "        to_print.append(\"- loss (instantaneous): \")\n",
        "        to_print.append(loss)\n",
        "        to_print.append(\"- policy accuracy: \")\n",
        "        to_print.append(metric.result())\n",
        "        print(to_print)\n",
        "\n",
        "        metric.reset_states()\n",
        "\n",
        "    total_loss += loss\n",
        "\n",
        "    print(time()-tic)\n",
        "\n",
        "    return total_loss, total_steps\n",
        "\n",
        "\n",
        "def train_loop():\n",
        "    filled_up = 0\n",
        "\n",
        "    fixed_model = tf.keras.models.load_model(path_fixed_model)\n",
        "    updating_model = tf.keras.models.load_model(path_updating_model)\n",
        "\n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir = \"logs/self-play\", \n",
        "        write_graph = False,\n",
        "        write_steps_per_second = True,\n",
        "        update_freq = steps_per_update\n",
        "    )\n",
        "    tb_callback.set_model(updating_model)\n",
        "\n",
        "    lr_boundaries = [100000, 300000, 500000]    # from paper\n",
        "    lr_values = [0.2, 0.02, 0.002, 0.0002]      # from paper\n",
        "    lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_boundaries, lr_values)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_scheduler)\n",
        "\n",
        "    loss_policy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # from paper\n",
        "    loss_value = tf.keras.losses.MeanSquaredError()                     # from paper\n",
        "\n",
        "    metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    tot_moves = 0\n",
        "    tot_games = 0\n",
        "\n",
        "    while steps < TOTAL_STEPS:\n",
        "\n",
        "        n_moves, filled_up = play_parallel_games_apply(fixed_model, NUM_PARALLEL_GAMES, filled_up)\n",
        "        tot_moves += n_moves\n",
        "        tot_games += NUM_PARALLEL_GAMES\n",
        "        mean_length_game = tot_moves/tot_games\n",
        "\n",
        "        for i in NUM_TRAINING_STEPS:\n",
        "            steps += NUM_TRAINING_STEPS\n",
        "            cycle_loss, cycle_steps = train_step(updating_model, filled_up, optimizer, loss_policy, loss_value, metric, steps)\n",
        "\n",
        "        if steps % steps_per_update == 0:\n",
        "                updating_model.save(path_updating_model, save_traces=False) # should decrease saving time, since we don't have custome layers/models\n",
        "                fixed_model = tf.keras.models.load_model(path_updating_model)\n",
        "        \n",
        "        if steps % steps_per_eval == 0:\n",
        "                updating_model.save(path_checkpoints_for_evaluation.format(steps), save_traces=False)\n",
        "\n",
        "        steps += NUM_TRAINING_STEPS\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: try num games in parallel vs. time\n",
        "# TODO: see if you can evaluate until games finish playing"
      ],
      "metadata": {
        "id": "SfFkDLWvvjLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et8v7NWjpPlO",
        "outputId": "92b54c44-0eea-4fd8-a7f0-7b88cb25ee7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 47.4 s per loop\n",
            "1 loop, best of 5: 47.1 s per loop\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from time import time, sleep\n",
        "from multiprocessing import Pool\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(1))\n",
        "output = tf.keras.layers.Dense(1)(input)\n",
        "\n",
        "model = tf.keras.Model(inputs=input, outputs=output)\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam'\n",
        ")\n",
        "\n",
        "def eval(model):\n",
        "    # print(time())\n",
        "    sleep(np.random.random()*5)\n",
        "    return [model(np.zeros(1)), model(np.ones(1))]\n",
        "\n",
        "def play_parallel_games_apply(model, experience_buffer, num_games):\n",
        "    with Pool() as pool: # play as many games as possible in parallel, and add them to the queue\n",
        "        futures = [pool.apply_async(eval, [model]) for w in range(num_games)]\n",
        "        for f in futures:\n",
        "            result = f.get()\n",
        "            for part in result:\n",
        "                experience_buffer.append(part)\n",
        "\n",
        "def play_parallel_games_imap(model, experience_buffer, num_games):\n",
        "    with Pool() as pool: # play as many games as possible in parallel, and add them to the queue\n",
        "        futures = pool.imap_unordered(eval, [model]*num_games)\n",
        "        for f in futures:\n",
        "            result = f\n",
        "            for part in result:\n",
        "                experience_buffer.append(part)\n",
        "\n",
        "l = []\n",
        "%timeit play_parallel_games_apply(model, l, 50)\n",
        "l = []\n",
        "%timeit play_parallel_games_imap(model, l, 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "utils.gen()"
      ],
      "metadata": {
        "id": "pMM-P-_j18DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import default_rng\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "qty = 10000\n",
        "\n",
        "rng = default_rng()\n",
        "labels = np.zeros((8*8*73))\n",
        "labels[0] = 1\n",
        "labels = [labels]*qty\n",
        "predict_array = np.zeros((8*8*73))\n",
        "predictions = []\n",
        "for i in range(qty):\n",
        "    predict_array = np.random.random_sample((8*8*73))*2-1\n",
        "    # predict_array /= np.sum(predict_array)\n",
        "    predictions.append(predict_array)\n",
        "    # idx = rng.choice(range(8*8*73))\n",
        "    # predict_array[idx] = 1\n",
        "    # predictions.append(predict_array.copy())\n",
        "    # predict_array[idx] = 0\n",
        "\n",
        "print(np.sum([np.sum(p) for p in predictions]))\n",
        "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "bce(labels, predictions).numpy()\n"
      ],
      "metadata": {
        "id": "unTlsTuBEaBU",
        "outputId": "13f7996e-1cbe-4d8d-fcae-0b8c45279149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4911.572229639013\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-bbd0d0f40c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m73\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'log' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "qty = 10000\n",
        "\n",
        "# labels = np.zeros((qty,3))\n",
        "# labels[:, 0] = 45\n",
        "# labels[:, 1] = 1\n",
        "# labels[:, 2] = 300\n",
        "\n",
        "# predictions = np.random.rand(qty, 8, 8, 73)\n",
        "# print(labels.shape)\n",
        "# print(predictions.shape)\n",
        "# # bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "# # bce(labels, predictions).numpy()\n",
        "\n",
        "# cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# cce(labels, predictions).numpy()\n",
        "\n",
        "x = np.zeros((8, 8, 8, 73))\n",
        "x[0, 2, 3, 5] = 1\n",
        "# x= np.array(x)\n",
        "\n",
        "\n",
        "lay = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "print(lay)"
      ],
      "metadata": {
        "id": "EFUrtHf_Pg9B",
        "outputId": "4600f6b1-9c82-43e1-d4a9-140661159ed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(8, 4672), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_x = 2\n",
        "arr_y = 3\n",
        "arr_z = 5\n",
        "\n",
        "print(x[0, arr_x, arr_y, arr_z])\n",
        "idx = np.ravel_multi_index([arr_x, arr_y, arr_z], np.shape(x)[1:])\n",
        "print(\"index\", idx)\n",
        "print(lay[0][idx].numpy() == x[0, arr_x, arr_y, arr_z])"
      ],
      "metadata": {
        "id": "6hT4ZN_PQOro",
        "outputId": "0291c026-7c08-4b12-ede0-67468fd7d5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "index 1392\n",
            "True\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "6ff546d1c5a7064c8e32c19edaef78491647a0db70d1b75d69edec23d383707d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}