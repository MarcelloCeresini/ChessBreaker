{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2060, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:02:05.951655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:05.979418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:05.979608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:05.980428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import chess, os, chess.pgn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "\n",
    "from model import ResNet, create_model\n",
    "import utils\n",
    "conf = utils.Config()\n",
    "\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(path=None):\n",
    "    path = path.decode(\"utf-8\")\n",
    "    planes = None\n",
    "    output_array = np.zeros([*conf.BOARD_SHAPE, conf.N_PLANES], dtype=np.float32)\n",
    "    \n",
    "    if path == None:\n",
    "        database_path = '/home/marcello/github/ChessBreaker/data/Database'\n",
    "        files = glob.glob(os.path.join(database_path, '*.pgn'))\n",
    "    else:\n",
    "        files = [path]\n",
    "    \n",
    "    for filename in files:\n",
    "        with open(os.path.join(os.getcwd(), filename), 'r') as pgn:\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "\n",
    "            while game != None:\n",
    "                whole_game_moves = game.game().mainline_moves()\n",
    "                result = utils.outcome(game.headers[\"Result\"])\n",
    "\n",
    "                board = chess.Board()\n",
    "                board_history = [board.fen()[:-6]]\n",
    "                \n",
    "                for move in whole_game_moves:\n",
    "                    # the input is the PREVIOUS board\n",
    "                    planes = utils.update_planes(planes, board, board_history)\n",
    "                    # inputs.append(planes)\n",
    "                    \n",
    "                    # the output is the move from that position\n",
    "                    mask = utils.mask_moves([move])[0]\n",
    "                    output_array[mask[0], mask[1], mask[2]] = 1\n",
    "                    # outputs.append(output_array)\n",
    "\n",
    "                    # oss: input = planes, output = (moves + result)!!\n",
    "                    yield (planes, (output_array, result)) ### yield before resetting the output\n",
    "\n",
    "                    output_array[mask[0], mask[1], mask[2]] = 0\n",
    "                    \n",
    "                    # then you actually push the move preparing for next turn\n",
    "                    board.push(move)\n",
    "                    board_history.append(board.fen()[:-6])\n",
    "                \n",
    "                game = chess.pgn.read_game(pgn)\n",
    "\n",
    "# avg = np.average([info[file, \"games\"] for file in info.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 20:02:06.079227: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-21 20:02:06.080291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:06.080540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:06.080661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:06.471878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:06.472050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:06.472318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 20:02:06.472424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3524 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert 800000.0 to EagerTensor of dtype int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/marcello/github/ChessBreaker/imitation_learning.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/imitation_learning.ipynb#ch0000002?line=12'>13</a>\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_generator(gen, output_signature\u001b[39m=\u001b[39moutput_signature)                            \u001b[39m# training is 313'831'972 moves\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/imitation_learning.ipynb#ch0000002?line=14'>15</a>\u001b[0m val_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_generator(gen, output_signature\u001b[39m=\u001b[39moutput_signature, args\u001b[39m=\u001b[39m[val_file_path])  \u001b[39m# validation is 446'402 moves --> we don't want to loose to much time\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/imitation_learning.ipynb#ch0000002?line=16'>17</a>\u001b[0m ds \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mshuffle(conf\u001b[39m.\u001b[39;49mBATCH_DIM\u001b[39m*\u001b[39;49m\u001b[39m1e5\u001b[39;49m) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/imitation_learning.ipynb#ch0000002?line=17'>18</a>\u001b[0m     \u001b[39m.\u001b[39mbatch(conf\u001b[39m.\u001b[39mBATCH_DIM, num_parallel_calls\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/imitation_learning.ipynb#ch0000002?line=18'>19</a>\u001b[0m     \u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/imitation_learning.ipynb#ch0000002?line=20'>21</a>\u001b[0m val_ds \u001b[39m=\u001b[39m val_dataset\u001b[39m.\u001b[39mbatch(conf\u001b[39m.\u001b[39mBATCH_DIM\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, num_parallel_calls\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:1522\u001b[0m, in \u001b[0;36mDatasetV2.shuffle\u001b[0;34m(self, buffer_size, seed, reshuffle_each_iteration, name)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshuffle\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m   1454\u001b[0m             buffer_size,\n\u001b[1;32m   1455\u001b[0m             seed\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1456\u001b[0m             reshuffle_each_iteration\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1457\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1458\u001b[0m   \u001b[39m\"\"\"Randomly shuffles the elements of this dataset.\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m \n\u001b[1;32m   1460\u001b[0m \u001b[39m  This dataset fills a buffer with `buffer_size` elements, then randomly\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1522\u001b[0m   \u001b[39mreturn\u001b[39;00m ShuffleDataset(\n\u001b[1;32m   1523\u001b[0m       \u001b[39mself\u001b[39;49m, buffer_size, seed, reshuffle_each_iteration, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4849\u001b[0m, in \u001b[0;36mShuffleDataset.__init__\u001b[0;34m(self, input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001b[0m\n\u001b[1;32m   4847\u001b[0m \u001b[39m\"\"\"See `Dataset.shuffle()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m   4848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m-> 4849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_size \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m   4850\u001b[0m     buffer_size, dtype\u001b[39m=\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mint64, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbuffer_size\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   4851\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_seed, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_seed2 \u001b[39m=\u001b[39m random_seed\u001b[39m.\u001b[39mget_seed(seed)\n\u001b[1;32m   4852\u001b[0m \u001b[39mif\u001b[39;00m reshuffle_each_iteration \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1640\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1631\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1632\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1633\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1637\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1639\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1640\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1642\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1643\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     47\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 800000.0 to EagerTensor of dtype int64"
     ]
    }
   ],
   "source": [
    "# train_file_path = \"/home/marcello/github/ChessBreaker/data/Database/lichess_elite_2014-11.pgn\"  # 19547 samples\n",
    "\n",
    "val_file_path = \"/home/marcello/github/ChessBreaker/data/Database/lichess_elite_2015-12.pgn\"    # 446'402 samples\n",
    "\n",
    "output_signature=(\n",
    "    tf.TensorSpec((8,8,119), dtype=tf.dtypes.float16),\n",
    "    (\n",
    "        tf.TensorSpec((8,8,73), dtype=tf.dtypes.float32),\n",
    "        tf.TensorSpec((1,), dtype=tf.dtypes.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(gen, output_signature=output_signature)                            # training is 313'831'972 moves\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(gen, output_signature=output_signature, args=[val_file_path])  # validation is 446'402 moves --> we don't want to loose to much time\n",
    "\n",
    "ds = dataset.shuffle(conf.BATCH_DIM*int(1e5)) \\\n",
    "    .batch(conf.BATCH_DIM, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_dataset.batch(conf.BATCH_DIM*2, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.Input(shape=(8,8,119))\n",
    "# x =         tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "# output1 =   tf.keras.layers.Conv2D(73,  3, padding=\"same\", activation=\"relu\")(x)\n",
    "# output2 =   tf.keras.layers.Dense(1,       activation=\"relu\")(x)\n",
    "# model = tf.keras.Model(inputs=inputs, outputs=[output1, output2], name=\"try1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet()\n",
    "model = create_model()\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "losses = {\n",
    "\t\"action_values\": tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "\t\"state_value\": tf.keras.losses.MeanSquaredError(),\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"action_values\": tf.keras.metrics.BinaryCrossentropy()\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.1, \n",
    "        patience=8, \n",
    "        min_lr=1e-5\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"tmp/checkpoint\",\n",
    "        monitor='val_loss',\n",
    "        save_freq='epoch'\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='logs'\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = losses,\n",
    "    metrics = metrics,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8, 8, 119)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 8, 128)    15360       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 8, 8, 128)   512         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 8, 8, 128)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 256)    295168      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 256)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 128)    32896       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 128)    15360       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 128)    0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 128)   512         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 128)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 256)    33024       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 256)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 8, 512)    1180160     ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 8, 8, 256)    131328      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 256)    33024       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 8, 8, 256)    0           ['conv2d_6[0][0]',               \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 256)   1024        ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 8, 8, 256)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 512)    131584      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 1024)   4719616     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 8, 8, 1024)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 512)    524800      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 8, 8, 512)    0           ['conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 512)   2048        ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 8, 8, 512)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 1)      513         ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " global_max_pooling2d (GlobalMa  (None, 1)           0           ['conv2d_12[0][0]']              \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " action_values (Conv2D)         (None, 8, 8, 73)     37449       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " state_value (Lambda)           (None, 1)            0           ['global_max_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,296,202\n",
      "Trainable params: 7,289,034\n",
      "Non-trainable params: 7,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \"mini_resnet.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8, 119)\n",
      "(8, 8, 8, 73)\n",
      "<dtype: 'float32'>\n",
      "(8, 1)\n",
      "<dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 19:39:20.828862: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8, 8, 73)\n",
      "<dtype: 'float16'>\n",
      "(8, 1)\n",
      "<dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "sam = 0\n",
    "for sample in ds.take(1):\n",
    "    planes, (move, outcome) = sample\n",
    "    print(np.shape(planes))\n",
    "    print(np.shape(move))\n",
    "    print(move.dtype)\n",
    "    print(np.shape(outcome))\n",
    "    print(move.dtype)\n",
    "\n",
    "    move, outcome = model(planes)\n",
    "    print(np.shape(move))\n",
    "    print(move.dtype)\n",
    "    print(np.shape(outcome))\n",
    "    print(move.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "235/235 [==============================] - 19s 57ms/step - loss: 41.8040 - action_values_loss: 2.0010 - state_value_loss: 2.0230 - action_values_binary_crossentropy: 1.6051 - val_loss: 37.4624 - val_action_values_loss: 0.7645 - val_state_value_loss: 1.8255 - val_action_values_binary_crossentropy: 0.0033\n",
      "Epoch 2/3\n",
      "235/235 [==============================] - 14s 59ms/step - loss: 10.3490 - action_values_loss: 0.4189 - state_value_loss: 1.2554 - action_values_binary_crossentropy: 0.1269 - val_loss: 2.9662 - val_action_values_loss: 0.2884 - val_state_value_loss: 0.8843 - val_action_values_binary_crossentropy: 0.1130\n",
      "Epoch 3/3\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 2.4146 - action_values_loss: 0.3692 - state_value_loss: 0.9925 - action_values_binary_crossentropy: 0.1425 - val_loss: 2.9000 - val_action_values_loss: 0.3261 - val_state_value_loss: 1.3221 - val_action_values_binary_crossentropy: 0.1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68843b9190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = 60,\n",
    "    steps_per_epoch = int(5e6),\n",
    "    workers = 16,\n",
    "    use_multiprocessing = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ff546d1c5a7064c8e32c19edaef78491647a0db70d1b75d69edec23d383707d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
