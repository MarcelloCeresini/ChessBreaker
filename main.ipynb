{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcelloCeresini/ChessBreaker/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j2iWAxgCHN7z"
      },
      "outputs": [],
      "source": [
        "username = 'MarcelloCeresini'\n",
        "repository = 'ChessBreaker'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG5cfeYvHhdU",
        "outputId": "4cec9cda-4545-477d-ac07-85fa2a62972b"
      },
      "outputs": [],
      "source": [
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "    #%cd /content/drive/MyDrive/GitHub/\n",
        "    !git clone https://github.com/{username}/{repository}.git\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "    !pip3 install anytree\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qDwSWUnXcjn",
        "outputId": "dcf82176-ac9a-4f0c-cf94-8a54e2ef0ba8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-23 18:33:47.174160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "g1h3\n",
            "g1f3\n",
            "b1c3\n",
            "b1a3\n",
            "h2h3\n",
            "g2g3\n",
            "f2f3\n",
            "e2e3\n",
            "d2d3\n",
            "c2c3\n",
            "b2b3\n",
            "a2a3\n",
            "h2h4\n",
            "g2g4\n",
            "f2f4\n",
            "e2e4\n",
            "d2d4\n",
            "c2c4\n",
            "b2b4\n",
            "a2a4\n",
            "<LegalMoveGenerator at 0x7ff6253fadf0 (Nh3, Nf3, Nc3, Na3, h3, g3, f3, e3, d3, c3, b3, a3, h4, g4, f4, e4, d4, c4, b4, a4)>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-23 18:33:47.234658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.234948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.236892: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-06-23 18:33:47.239467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.240379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.240890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.899852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.900189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.900324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 18:33:47.900457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3607 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import chess\n",
        "from anytree import Node\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import ray\n",
        "\n",
        "import utils\n",
        "from utils import plane_dict, Config, x_y_from_position\n",
        "from model import ResNet\n",
        "\n",
        "conf = Config()\n",
        "board = chess.Board()\n",
        "\n",
        "legal_moves = board.legal_moves\n",
        "for move in legal_moves:\n",
        "    print(move.uci())  \n",
        "print(legal_moves)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 0.0070400238037109375\n",
            "5 0.007706403732299805\n",
            "5 0.00787663459777832\n",
            "5 0.007958412170410156\n",
            "None\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'ray._raylet.ObjectRef' object has no attribute 'get_action_value'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/home/marcello/github/ChessBreaker/main.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000011?line=21'>22</a>\u001b[0m future \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mupdate_action_value\u001b[39m.\u001b[39mremote(\u001b[39m7\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000011?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(ray\u001b[39m.\u001b[39mget(future))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000011?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(future\u001b[39m.\u001b[39;49mget_action_value\u001b[39m.\u001b[39mremote())\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ray._raylet.ObjectRef' object has no attribute 'get_action_value'"
          ]
        }
      ],
      "source": [
        "# trying ray functionalities\n",
        "tic = time()\n",
        "@ray.remote\n",
        "def my_function(i):\n",
        "    return i\n",
        "\n",
        "future = my_function.remote(5)\n",
        "\n",
        "for i in range(4):\n",
        "    print(ray.get(future), time()-tic)\n",
        "\n",
        "@ray.remote\n",
        "class MyNode2(Node):\n",
        "    \n",
        "    def update_action_value(self, action_value):\n",
        "        self.action_value = action_value\n",
        "\n",
        "    def get_action_value(self):\n",
        "        return self.action_value\n",
        "\n",
        "node = MyNode2.remote(\"root\")\n",
        "future = node.update_action_value.remote(7)\n",
        "print(ray.get(future))\n",
        "print(future.get_action_value.remote())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The idea shoul be to instantiate a function MCTS that uses the same actor, the root node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@ray.remote\n",
        "def MCTS_func(root_node):\n",
        "    pass\n",
        "\n",
        "root_node = MyNode2.remote()\n",
        "\n",
        "[MCTS_func.remote(root_node) for _ in range(16)] # number of cores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgK8epdnlt7y",
        "outputId": "7b699a00-5e07-4532-a13d-b4bf34cea97b"
      },
      "outputs": [],
      "source": [
        "# print(board.fen())\n",
        "print(list(board.pieces(1,True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3TOlR3jMn4v",
        "outputId": "28bfd60e-ed09-4733-bef3-4e0cc79341fb"
      },
      "outputs": [],
      "source": [
        "def uniform_tensor(x):\n",
        "    return tf.fill(conf.BOARD_SHAPE, x)\n",
        "\n",
        "def special_input_planes(board):                                    # not repeated planes\n",
        "    return tf.transpose(tf.vectorized_map(                          # vectorized_map = map_fn but in parallel (just a tad faster) \n",
        "            uniform_tensor,\n",
        "            tf.constant([\n",
        "                int(board.turn                                 ),   # whose turn it is\n",
        "                int(board.fullmove_number-1                    ),   # don't know why but it starts from 1 on move 1, just reduce it by one and now it's right (MAX 255, using uint8!!)\n",
        "                int(board.has_kingside_castling_rights(True)   ),   # True for White\n",
        "                int(board.has_queenside_castling_rights(True)  ),\n",
        "                int(board.has_kingside_castling_rights(False)  ),   # False for Black\n",
        "                int(board.has_queenside_castling_rights(False) ),\n",
        "                int(board.halfmove_clock                       )    # number of moves from last capture / pawn move --> reaching 50 means draw\n",
        "            ], dtype=conf.PLANES_DTYPE)\n",
        "        ), [1,2,0])                                                 # transpose to have plane number last --> in order to concat them\n",
        "\n",
        "\n",
        "def update_planes(current, board, board_history):\n",
        "\n",
        "    if current == None: # root, initialize to zero\n",
        "        current = tf.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES], dtype=conf.PLANES_DTYPE)\n",
        "    \n",
        "    planes = [] # since we cannot \"change\" a tensor after creating it, we create them one by one in a list and then stack them\n",
        "\n",
        "    for color in range(2):                                                                                                  # for each color\n",
        "        for piece_type in range(1, conf.N_PIECE_TYPES+1):                                                                   # for each piece type\n",
        "            indices = []                                                                                                    # --> we save the position on the board in a list\n",
        "            for position in list(board.pieces(piece_type, color)):                                                          # for each piece of that type\n",
        "                indices.append(x_y_from_position(position))                                                                 # the function transforms a number (1-64) into a tuple (1-8, 1-8)\n",
        "            if len(indices) == 0:\n",
        "                tensor = uniform_tensor(tf.constant(0, dtype=conf.PLANES_DTYPE))\n",
        "            else:    \n",
        "                values = np.array([1]*len(indices), dtype=conf.PLANES_DTYPE_NP) # simply \"1\" in a list with unit8 dtype\n",
        "                tensor = tf.sparse.to_dense(tf.SparseTensor(dense_shape=[*conf.BOARD_SHAPE], indices=indices, values=values))   ### created as sparse because it's easier, needed as dense afterwards\n",
        "            planes.append(tensor)\n",
        "        planes.append(uniform_tensor(tf.constant(board_history.count(board_history[-1]), dtype=conf.PLANES_DTYPE)))         # adding a \"repetition plane\" for each color (simply count how many times the current (last) position has been encountered)\n",
        "\n",
        "    # 1 stack\n",
        "    current_planes = tf.transpose(tf.stack(planes), [1,2,0])                                                                # transpose them to have the planes as last dimension\n",
        "    # 7 stacks (total 8 repetitions)\n",
        "    old_planes = tf.slice(current, begin=[0,0,0], size=[*conf.BOARD_SHAPE, (conf.PAST_TIMESTEPS-1)*conf.REPEATED_PLANES])   # take the first 7 repetitions, slice them and paste them at the end of the new planes (last is discarded, as are special planes)\n",
        "    \n",
        "    return tf.concat([current_planes, old_planes, special_input_planes(board)], axis=-1)    # also concat the special planes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv2zcMiUh9bU"
      },
      "outputs": [],
      "source": [
        "@ray.remote\n",
        "class MyNode(Node): # subclassing Node from Anytree to add some methods\n",
        "\n",
        "    def update_action_value(self, new_action_value):                                                        # used during backtracking to update action value if the simulation reached the end through that node\n",
        "        self.action_value += (new_action_value-self.action_value)/(self.visit_count+1)                      # simply the mean value, but computed iteratively\n",
        "\n",
        "    def calculate_upper_confidence_bound(self, num_total_iterations=1):                                     # Q + U --> U proportional to P/(1+N) --> parameter decides exploration vs. exploitation\n",
        "        return self.action_value + conf.expl_param(num_total_iterations)*self.prior/(1+self.visit_count)\n",
        "\n",
        "    def calculate_move_probability(self, num_total_iterations=1):                                           # N^(1/tau) --> tau is a temperature parameter (exploration vs. exploitation)\n",
        "        return self.visit_count**(1/conf.temp_param(num_total_iterations))\n",
        "\n",
        "@ray.remote\n",
        "def MTCS(model, root_node, max_depth, num_restarts):\n",
        "    print(root_node.name)\n",
        "    INIT_ROOT = root_node\n",
        "    # for i in tqdm(range(num_restarts)):                                                                           # number of times to explore up until max_depth\n",
        "    for i in range(num_restarts):\n",
        "        root_node = INIT_ROOT\n",
        "        while root_node.depth <= max_depth:                                                                 # while depth < max --> descend\n",
        "            legal_moves = list(root_node.board.legal_moves)\n",
        "            # TODO: implement \"complete game\" inside MTCS --> stop the descent and give 1 as outcome (1/-1 depends)\n",
        "            assert root_node.depth >= 0 and root_node.depth <= max_depth, \"depth is wrong\"          \n",
        "\n",
        "            if root_node.is_leaf:                                                                           # if it's leaf --> need to pass the position (planes) through the model, to get priors (action_values) and outcome (state_value)\n",
        "                full_moves, outcome = model(tf.expand_dims(root_node.planes, axis=0))\n",
        "                priors = tf.boolean_mask(full_moves, utils.mask_moves(legal_moves))                         # boolean mask returns a tensor of only the values that were masked (as a list let's say)\n",
        "\n",
        "                root_node.action_value = outcome                                                            # the activation value of a leaf node is the state_value computed by the network\n",
        "\n",
        "                for move, prior in zip(legal_moves, priors):                                                # creating children\n",
        "                    root_board_fen = root_node.board.fen()\n",
        "                    new_board = chess.Board()\n",
        "                    new_board.set_fen(root_board_fen)\n",
        "                                                                          # each with their board (by pushing the move)\n",
        "                    new_board.push(move)\n",
        "                    new_board_history = root_node.board_history.copy()                                      # and board history! (copy because list are pointers)\n",
        "                    new_board_history.append(new_board.fen()[:-6])\n",
        "                    MyNode(\n",
        "                        move, \n",
        "                        parent = root_node,                                                                 # very important to build the tree\n",
        "                        prior = prior,                                                                      # prior is the \"initial\" state_value of a node\n",
        "                        visit_count = 0,                                                                    # initialize visit_count to 0\n",
        "                        action_value = 0,\n",
        "                        board = new_board, \n",
        "                        board_history = new_board_history,                                                  \n",
        "                        planes = update_planes(root_node.planes, new_board, new_board_history)              # update the planes --> each node stores its input planes!\n",
        "                    )\n",
        "\n",
        "            if root_node.depth < max_depth:                                                                 # if we are normally descending\n",
        "                children = root_node.children                                                               # get all the children (always != [])\n",
        "                \n",
        "                values = [child.calculate_upper_confidence_bound() for child in children]\n",
        "                root_node = children[np.argmax(values)]\n",
        "                # print(root_node, root_node.depth, max_depth)\n",
        "                root_node.visit_count += 1\n",
        "\n",
        "            else:    \n",
        "                outcome = root_node.action_value # needed for when depth=max_depth AND NOT LEAF (that means, already visited leaf) --> don't REDO the evaluation, it would give the same result, simply copy it from before\n",
        "                break                            # no need to descend the tree further, max depth is reached\n",
        "           \n",
        "        # barckpropagation of action value through the tree\n",
        "        while root_node.parent != INIT_ROOT:\n",
        "            assert root_node.depth >= 0 and root_node.depth <= max_depth, \"depth is wrong\"\n",
        "            root_node = root_node.parent\n",
        "            root_node.update_action_value(outcome)\n",
        "\n",
        "    return INIT_ROOT\n",
        "\n",
        "\n",
        "def choose_move(root_node):\n",
        "    children = root_node.children\n",
        "    assert root_node.children != [], \"No children, cannot choose move\"\n",
        "    p = [child.calculate_move_probability() for child in children] # normalize probabilities\n",
        "    p_norm = [i/sum(p) for i in p]\n",
        "    root_node = np.random.choice(\n",
        "        children, \n",
        "        p = p_norm  # choose the child proportionally to the number of times it has been visited (exponentiated by a temperature parameter)\n",
        "    ) \n",
        "        \n",
        "    root_node.parent = None # To detach the subtree and restart with the next move search\n",
        "\n",
        "    return root_node\n",
        "\n",
        "\n",
        "def complete_game(model):\n",
        "    move_list = []\n",
        "    board = chess.Board()\n",
        "    board_history = [board.fen()[:-6]]                           # we remove the \"en passant\", \"halfmove clock\" and \"fullmove number\" from the fen --> position will be identical even if those values differ\n",
        "    root_node = MyNode(\n",
        "        \"\",                                                     # no name needed for initial position\n",
        "        board = board,\n",
        "        board_history = board_history,\n",
        "        planes = update_planes(None, board, board_history),    # start from empty planes and fill them (usually you need previous planes to fill them)\n",
        "        action_value=0)\n",
        "\n",
        "    while not root_node.board.is_game_over(claim_draw=True) and root_node.board.fullmove_number <= conf.MAX_MOVE_COUNT:\n",
        "        \n",
        "        root_node = MTCS(model, root_node, max_depth = conf.MAX_DEPTH, num_restarts=conf.NUM_RESTARTS)                          # though the root node you can access all the tree\n",
        "        root_node = choose_move(root_node)\n",
        "        move_list.append(root_node.name)\n",
        "    \n",
        "    return move_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ResNet()\n",
        "print(model(conf.DUMMY_INPUT)[0].shape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "moves = complete_game(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "moves2 = moves.copy()\n",
        "board = chess.Board()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board.push(moves2.pop(0))\n",
        "board"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMu73IMlerhIT1uChZ4Lk90",
      "include_colab_link": true,
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
