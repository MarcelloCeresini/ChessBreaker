{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcelloCeresini/ChessBreaker/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j2iWAxgCHN7z"
      },
      "outputs": [],
      "source": [
        "username = 'MarcelloCeresini'\n",
        "repository = 'ChessBreaker'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG5cfeYvHhdU",
        "outputId": "15c7d15b-534b-4141-85c0-0e45928b136a"
      },
      "outputs": [],
      "source": [
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "    #%cd /content/drive/MyDrive/GitHub/\n",
        "    !git clone https://github.com/{username}/{repository}.git\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "    !pip3 install anytree\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5qDwSWUnXcjn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-19 17:58:16.557485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.585341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.585582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.587050: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-07-19 17:58:16.588504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.588797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.589009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.984297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.984461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.984577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-19 17:58:16.984686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 488 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import chess\n",
        "from anytree import Node\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import utils\n",
        "from utils import plane_dict, Config, x_y_from_position\n",
        "from model import ResNet\n",
        "\n",
        "conf = Config()\n",
        "board = chess.Board()\n",
        "\n",
        "# legal_moves = board.legal_moves\n",
        "# for move in legal_moves:\n",
        "#     print(move.uci())  \n",
        "# print(legal_moves)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W3TOlR3jMn4v"
      },
      "outputs": [],
      "source": [
        "def special_input_planes(board):                                    # not repeated planes\n",
        "    \n",
        "    special_planes = np.zeros([*conf.BOARD_SHAPE, conf.SPECIAL_PLANES], conf.PLANES_DTYPE_NP)\n",
        "    special_planes[:,:,0] = board.turn                                 \n",
        "    special_planes[:,:,1] = board.fullmove_number-1                    \n",
        "    special_planes[:,:,2] = board.has_kingside_castling_rights(True)   \n",
        "    special_planes[:,:,3] = board.has_queenside_castling_rights(True)  \n",
        "    special_planes[:,:,4] = board.has_kingside_castling_rights(False)  \n",
        "    special_planes[:,:,5] = board.has_queenside_castling_rights(False) \n",
        "    special_planes[:,:,6] = board.halfmove_clock                       \n",
        "    \n",
        "    # special_planes = np.stack([\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.turn                                 ), conf.PLANES_DTYPE_NP),   # whose turn it is\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.fullmove_number-1                    ), conf.PLANES_DTYPE_NP),   # don't know why but it starts from 1 on move 1, just reduce it by one and now it's right (MAX 255, using uint8!!)\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_kingside_castling_rights(True)   ), conf.PLANES_DTYPE_NP),   # True for White\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_queenside_castling_rights(True)  ), conf.PLANES_DTYPE_NP),\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_kingside_castling_rights(False)  ), conf.PLANES_DTYPE_NP),   # False for Black\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_queenside_castling_rights(False) ), conf.PLANES_DTYPE_NP),\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.halfmove_clock                       ), conf.PLANES_DTYPE_NP)    # number of moves from last capture / pawn move --> reaching 50 means draw\n",
        "    # ])\n",
        "\n",
        "    return special_planes                                            # transpose to have plane number last --> in order to concat them\n",
        "\n",
        "\n",
        "# def update_planes(current, board, board_history):\n",
        "\n",
        "#     if current == None: # root, initialize to zero\n",
        "#         current = tf.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES], dtype=conf.PLANES_DTYPE)\n",
        "    \n",
        "#     planes = [] # since we cannot \"change\" a tensor after creating it, we create them one by one in a list and then stack them\n",
        "\n",
        "#     for color in range(2):                                                                                                  # for each color\n",
        "#         for piece_type in range(1, conf.N_PIECE_TYPES+1):                                                                   # for each piece type\n",
        "#             indices = []                                                                                                    # --> we save the position on the board in a list\n",
        "#             for position in list(board.pieces(piece_type, color)):                                                          # for each piece of that type\n",
        "#                 indices.append(x_y_from_position(position))                                                                 # the function transforms a number (1-64) into a tuple (1-8, 1-8)\n",
        "#             if len(indices) == 0:\n",
        "#                 tensor = uniform_tensor(tf.constant(0, dtype=conf.PLANES_DTYPE))\n",
        "#             else:\n",
        "#                 values = np.array([1]*len(indices), dtype=conf.PLANES_DTYPE_NP) # simply \"1\" in a list with unit8 dtype\n",
        "#                 tensor = tf.sparse.to_dense(tf.SparseTensor(dense_shape=[*conf.BOARD_SHAPE], indices=indices, values=values))   ### created as sparse because it's easier, needed as dense afterwards\n",
        "#             planes.append(tensor)\n",
        "#         planes.append(uniform_tensor(tf.constant(board_history.count(board_history[-1]), dtype=conf.PLANES_DTYPE)))         # adding a \"repetition plane\" for each color (simply count how many times the current (last) position has been encountered)\n",
        "\n",
        "#     # 1 stack\n",
        "#     current_planes = tf.transpose(tf.stack(planes), [1,2,0])    \n",
        "#     print(tf.shape(current_planes))                                                            # transpose them to have the planes as last dimension\n",
        "#     # 7 stacks (total 8 repetitions)\n",
        "#     old_planes = tf.slice(current, begin=[0,0,0], size=[*conf.BOARD_SHAPE, (conf.PAST_TIMESTEPS-1)*conf.REPEATED_PLANES])   # take the first 7 repetitions, slice them and paste them at the end of the new planes (last is discarded, as are special planes)\n",
        "    \n",
        "#     return tf.concat([current_planes, old_planes, special_input_planes(board)], axis=-1)    # also concat the special planes\n",
        "\n",
        "def update_planes(old, board, board_history):\n",
        "\n",
        "    if type(old) != np.ndarray: # root, initialize to zero\n",
        "        old = np.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES], dtype=conf.PLANES_DTYPE_NP)\n",
        "    \n",
        "    total_planes = np.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES], dtype=conf.PLANES_DTYPE_NP) # since we cannot \"change\" a tensor after creating it, we create them one by one in a list and then stack them\n",
        "    plane = -1\n",
        "    \n",
        "    repetition_counter = board_history.count(board_history[-1])\n",
        "    for color in range(2):                                                                                                  # for each color\n",
        "        for piece_type in range(1, conf.N_PIECE_TYPES+1):                                                                   # for each piece type\n",
        "            plane += 1\n",
        "            indices = map(x_y_from_position, list(board.pieces(piece_type, color)))        # for each piece of that type                                                                                            # --> we save the position on the board in a list\n",
        "            # the function transforms a number (1-64) into a tuple (1-8, 1-8)\n",
        "            for idx in indices:\n",
        "                total_planes[idx[0], idx[1], plane] = 1\n",
        "        plane += 1\n",
        "        total_planes[:, :, plane] = repetition_counter    # adding a \"repetition plane\" for each color (simply count how many times the current (last) position has been encountered)\n",
        "   \n",
        "    # 7 stacks (total 8 repetitions)\n",
        "    to_keep = tf.slice(old, begin=[0,0,0], size=[*conf.BOARD_SHAPE, (conf.PAST_TIMESTEPS-1)*conf.REPEATED_PLANES])   # take the first 7 repetitions, slice them and paste them at the end of the new planes (last is discarded, as are special planes)\n",
        "    \n",
        "    total_planes[:, :, conf.REPEATED_PLANES:(conf.REPEATED_PLANES+conf.OLD_PLANES_TO_KEEP)] = old[:, :, :conf.OLD_PLANES_TO_KEEP]\n",
        "    total_planes[:, :, conf.REPEATED_PLANES+conf.OLD_PLANES_TO_KEEP:] = special_input_planes(board)\n",
        "    \n",
        "    return total_planes\n",
        "\n",
        "\n",
        "#0.04062032699584961\n",
        "# 0.0007264614105224609\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yv2zcMiUh9bU"
      },
      "outputs": [],
      "source": [
        "class MyNode(Node): # subclassing Node from Anytree to add some methods\n",
        "\n",
        "    def update_action_value(self, new_action_value):                                                        # used during backtracking to update action value if the simulation reached the end through that node\n",
        "        self.action_value += (new_action_value-self.action_value)/(self.visit_count+1)                      # simply the mean value, but computed iteratively\n",
        "\n",
        "    def calculate_upper_confidence_bound(self, num_total_iterations=1):                                     # Q + U --> U proportional to P/(1+N) --> parameter decides exploration vs. exploitation\n",
        "        return self.action_value + conf.expl_param(num_total_iterations)*self.prior/(1+self.visit_count)\n",
        "\n",
        "    def calculate_move_probability(self, num_total_iterations=1):                                           # N^(1/tau) --> tau is a temperature parameter (exploration vs. exploitation)\n",
        "        return self.visit_count**(1/conf.temp_param(num_total_iterations))\n",
        "\n",
        "\n",
        "def MTCS(model, root_node, max_depth, num_restarts):\n",
        "    '''\n",
        "        As it is written, the search descends until it finds a leaf to be evalued, then restarts until it gathers a batch of evaluations\n",
        "        The descent, however, does not restart from the just evalued leafs, but always from the beginning (easier implementation)\n",
        "        This should IMPROVE exploration because the probability of entering a node is inversely proportional to the number of visits of that node\n",
        "    '''\n",
        "\n",
        "    print(root_node.name)\n",
        "    INIT_ROOT = root_node\n",
        "    # for i in tqdm(range(num_restarts)):                                                                           # number of times to explore up until max_depth\n",
        "    flag_restart = True # true if you haven't reached the number of total restarts\n",
        "    flag_max_depth = True\n",
        "    i = 0\n",
        "\n",
        "    leaf_node_batch = []\n",
        "    legal_moves_batch = []\n",
        "    \n",
        "    while flag_restart:\n",
        "        i+=1\n",
        "        if i >= num_restarts: flag_restart = False\n",
        "        root_node = INIT_ROOT\n",
        "        # print(\"-----------\")\n",
        "        \n",
        "        while root_node.depth <= max_depth and (flag_restart or flag_max_depth):  # while depth < max --> descend BUT STOP when you finished num_restarts AND the batch is empty AND you reach an already explored end of the tree with a subsequent descent\n",
        "            legal_moves = list(root_node.board.legal_moves)\n",
        "            # TODO: implement \"complete game\" inside MTCS --> stop the descent and give 1 as outcome (1/-1 depends)\n",
        "            \n",
        "            assert root_node.depth >= 0 and root_node.depth <= max_depth, \"depth is wrong\"          \n",
        "            flag_max_depth = True\n",
        "\n",
        "            if root_node.is_leaf:                                                                           # if it's leaf --> need to pass the position (planes) through the model, to get priors (action_values) and outcome (state_value)\n",
        "\n",
        "                if len(root_node.siblings) > 0:         # this part is to try and avoid batching the same node twice (so we evaluate a random sibling instead)\n",
        "                    leaf_node_name_list = [node.name for node in leaf_node_batch]\n",
        "                    if root_node.name in leaf_node_name_list:\n",
        "                        # print(\"sibling\")\n",
        "                        siblings_list = list(root_node.siblings)\n",
        "                        random_sibling = np.random.choice(siblings_list)\n",
        "                        while random_sibling.name in leaf_node_name_list and len(siblings_list)>1:\n",
        "                            siblings_list.remove(random_sibling) #do it with np.random in a range, and POP instead of remove\n",
        "                            random_sibling = np.random.choice(siblings_list)\n",
        "                        \n",
        "                        root_node = random_sibling\n",
        "                \n",
        "                leaf_node_batch.append(root_node)\n",
        "                legal_moves_batch.append(legal_moves)\n",
        "                root_node.visit_count += 1\n",
        "\n",
        "                # print(\"to be evaluated\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "\n",
        "                if len(leaf_node_batch) == conf.BATCH_DIM or root_node == INIT_ROOT:\n",
        "                    flag_batch = False\n",
        "\n",
        "\n",
        "                    plane_list = [root_node.planes for root_node in leaf_node_batch]\n",
        "                    # 0.0032072067260742188\n",
        "                    # 7.05718994140625e-05\n",
        "                    \n",
        "                    planes = np.stack(plane_list)\n",
        "\n",
        "                    full_moves_batch, outcome_batch = model(planes)\n",
        "\n",
        "                    full_moves_batch_np = full_moves_batch.numpy()\n",
        "                    outcome_batch_np = outcome_batch.numpy()\n",
        "\n",
        "                    def unstack(a, axis=0):\n",
        "                        return np.moveaxis(a, axis, 0)\n",
        "\n",
        "                    if np.shape(full_moves_batch_np)[0] != 1:\n",
        "                        full_moves_batch_np = unstack(full_moves_batch.numpy())\n",
        "                        outcome_batch_np = unstack(outcome_batch.numpy())\n",
        "\n",
        "                    #########################\n",
        "                    for root_node, full_moves, outcome, legal_moves in zip(leaf_node_batch, full_moves_batch_np, outcome_batch_np, legal_moves_batch):\n",
        "                        mask_idx = utils.mask_moves(legal_moves)\n",
        "                        priors = [full_moves[idx[0], idx[1], idx[2]] for idx in mask_idx]                        # boolean mask returns a tensor of only the values that were masked (as a list let's say)\n",
        "                        # 0.006434917449951172\n",
        "                        # 1.3113021850585938e-05\n",
        "                        root_node.action_value = outcome    \n",
        "\n",
        "                        for move, prior in zip(legal_moves, priors):                                                # creating children\n",
        "                            \n",
        "                            root_board_fen = root_node.board.fen()\n",
        "                            new_board = chess.Board()\n",
        "                            new_board.set_fen(root_board_fen)\n",
        "                                                                                  # each with their board (by pushing the move)\n",
        "                            new_board.push(move)\n",
        "                            new_board_history = root_node.board_history.copy()                                      # and board history! (copy because list are pointers)\n",
        "                            new_board_history.append(new_board.fen()[:-6])\n",
        "\n",
        "                            planes = update_planes(root_node.planes, new_board, new_board_history)\n",
        "                            \n",
        "                            MyNode(\n",
        "                                move.uci(), \n",
        "                                parent = root_node,                                                                 # very important to build the tree\n",
        "                                prior = prior,                                                                      # prior is the \"initial\" state_value of a node\n",
        "                                visit_count = 0,                                                                    # initialize visit_count to 0\n",
        "                                action_value = 0,\n",
        "                                board = new_board, \n",
        "                                board_history = new_board_history,                                                  \n",
        "                                planes = planes             # update the planes --> each node stores its input planes!\n",
        "                            )\n",
        "                            \n",
        "                    leaf_node_batch = []\n",
        "                    legal_moves_batch = []\n",
        "                    root_node = INIT_ROOT\n",
        "\n",
        "            else: # if it does not need to be evalued because it already has children \n",
        "                if root_node.depth < max_depth:                                                                 # if we are normally descending\n",
        "                    # print(\"choosing point\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                    children = root_node.children                                                               # get all the children (always != [])\n",
        "                    \n",
        "                    values = [child.calculate_upper_confidence_bound() for child in children]\n",
        "                    root_node = children[np.argmax(values)]\n",
        "                    root_node.visit_count += 1                                                                  # add 1 to the visit count of the chosen child\n",
        "                    # print(\"chosen node\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                else:\n",
        "                    print(\"final leaf\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                    flag_max_depth = False\n",
        "                    outcome = root_node.action_value    # needed for when depth=max_depth AND NOT LEAF (that means, already visited leaf) --> don't REDO the evaluation, it would give the same result, simply copy it from before\n",
        "                    break                               # it will leave the while, max depth is reached\n",
        "           \n",
        "        # print(\"num_restarts\", i, \" - flag_r\", flag_restart, \" - flag_md\", flag_max_depth)\n",
        "        # barckpropagation of action value through the tree\n",
        "        # print(\"outcome\", outcome)\n",
        "        while root_node.depth > 0:\n",
        "            # root node should be an already evalued leaf, at max depth (so OUTCOME has been set)\n",
        "            assert root_node.depth > 0 and root_node.depth <= max_depth, \"depth is wrong\"\n",
        "            root_node = root_node.parent\n",
        "            root_node.update_action_value(outcome)\n",
        "    return INIT_ROOT\n",
        "\n",
        "\n",
        "def choose_move(root_node):\n",
        "    children = root_node.children\n",
        "    assert root_node.children != [], \"No children, cannot choose move\"\n",
        "    p = [child.calculate_move_probability() for child in children] \n",
        "    p_norm = [i/sum(p) for i in p] # normalize probabilities\n",
        "    root_node = np.random.choice(\n",
        "        children, \n",
        "        p = p_norm  # choose the child proportionally to the number of times it has been visited (exponentiated by a temperature parameter)\n",
        "    ) \n",
        "        \n",
        "    root_node.parent = None # To detach the subtree and restart with the next move search\n",
        "\n",
        "    return root_node\n",
        "\n",
        "\n",
        "def complete_game(model):\n",
        "    move_list = []\n",
        "    board = chess.Board()\n",
        "    board_history = [board.fen()[:-6]]                           # we remove the \"en passant\", \"halfmove clock\" and \"fullmove number\" from the fen --> position will be identical even if those values differ\n",
        "    root_node = MyNode(\n",
        "        \"Start\",                                                     # no name needed for initial position\n",
        "        board = board,\n",
        "        board_history = board_history,\n",
        "        planes = update_planes(None, board, board_history),    # start from empty planes and fill them (usually you need previous planes to fill them)\n",
        "        action_value=0,\n",
        "        visit_count=0\n",
        "        )\n",
        "\n",
        "    while not root_node.board.is_game_over(claim_draw=True) and root_node.board.fullmove_number <= conf.MAX_MOVE_COUNT:\n",
        "        \n",
        "        root_node = MTCS(model, root_node, max_depth = conf.MAX_DEPTH, num_restarts=conf.NUM_RESTARTS)                          # though the root node you can access all the tree\n",
        "        root_node = choose_move(root_node)\n",
        "        move_list.append(root_node.name)\n",
        "    \n",
        "    return move_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNRD2BohKG2g",
        "outputId": "9c464466-c876-4ee8-de8f-4f18fee7f496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([  8   8   8 119], shape=(4,), dtype=int32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-19 17:58:17.655528: E tensorflow/stream_executor/cuda/cuda_blas.cc:232] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
            "2022-07-19 17:58:17.655565: E tensorflow/stream_executor/cuda/cuda_blas.cc:234] Failure to initialize cublas may be due to OOM (cublas needs some free memory when you initialize it, and your deep-learning framework may have preallocated more than its fair share), or may be because this binary was not built with support for the GPU in your machine.\n",
            "2022-07-19 17:58:17.655584: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:838 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Exception encountered when calling layer \"conv2d\" (type Conv2D).\n\nAttempting to perform BLAS operation using StreamExecutor without BLAS support [Op:Conv2D]\n\nCall arguments received by layer \"conv2d\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(8, 8, 8, 119), dtype=float32)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m/home/marcello/github/ChessBreaker/main.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000006?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ResNet()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000006?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(tf\u001b[39m.\u001b[39mshape(conf\u001b[39m.\u001b[39mDUMMY_INPUT))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000006?line=2'>3</a>\u001b[0m fm, ac \u001b[39m=\u001b[39m model(conf\u001b[39m.\u001b[39;49mDUMMY_INPUT)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000006?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfull moves shape\u001b[39m\u001b[39m\"\u001b[39m, fm\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcello/github/ChessBreaker/main.ipynb#ch0000006?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39maction values shape\u001b[39m\u001b[39m\"\u001b[39m, ac\u001b[39m.\u001b[39mshape)\n",
            "File \u001b[0;32m~/github/ChessBreaker/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/github/ChessBreaker/model.py:54\u001b[0m, in \u001b[0;36mResNet.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m---> 54\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock_1(inputs)\n\u001b[1;32m     55\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_2(x)\n\u001b[1;32m     56\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_3(x)\n",
            "File \u001b[0;32m~/github/ChessBreaker/model.py:20\u001b[0m, in \u001b[0;36mResNetBlock.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m---> 20\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_1(inputs)\n\u001b[1;32m     21\u001b[0m     x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mBatchNormalization()(x)\n\u001b[1;32m     22\u001b[0m     x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mActivation(\u001b[39m\"\u001b[39m\u001b[39mgelu\u001b[39m\u001b[39m\"\u001b[39m)(x)\n",
            "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n\nAttempting to perform BLAS operation using StreamExecutor without BLAS support [Op:Conv2D]\n\nCall arguments received by layer \"conv2d\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(8, 8, 8, 119), dtype=float32)"
          ]
        }
      ],
      "source": [
        "model = ResNet()\n",
        "print(tf.shape(conf.DUMMY_INPUT))\n",
        "fm, ac = model(conf.DUMMY_INPUT)\n",
        "print(\"full moves shape\", fm.shape)\n",
        "print(\"action values shape\", ac.shape)\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "1pHHpicUKG2h",
        "outputId": "dfaf3585-f2a2-476d-8b67-9b364e1d3a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/marcello/github/ChessBreaker/env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final leaf d 2 vc 2 name h7h5\n",
            "backprop 2.6464462280273438e-05\n",
            "final leaf d 2 vc 3 name f7f5\n",
            "backprop 2.86102294921875e-05\n",
            "final leaf d 2 vc 2 name b7b5\n",
            "backprop 3.7670135498046875e-05\n",
            "final leaf d 2 vc 2 name h7h5\n",
            "backprop 3.0517578125e-05\n",
            "final leaf d 2 vc 2 name c7c5\n",
            "backprop 2.5987625122070312e-05\n",
            "final leaf d 2 vc 2 name c7c5\n",
            "backprop 2.0503997802734375e-05\n",
            "final leaf d 2 vc 3 name b7b5\n",
            "backprop 3.0517578125e-05\n",
            "final leaf d 2 vc 3 name h7h5\n",
            "backprop 1.7881393432617188e-05\n",
            "final leaf d 2 vc 3 name f7f5\n",
            "backprop 1.7642974853515625e-05\n",
            "backprop 1.9073486328125e-06\n",
            "f2f4\n",
            "final leaf d 2 vc 2 name e2e4\n",
            "backprop 2.3365020751953125e-05\n",
            "final leaf d 2 vc 2 name d2d3\n",
            "backprop 2.6941299438476562e-05\n",
            "final leaf d 2 vc 2 name h2h4\n",
            "backprop 2.4318695068359375e-05\n",
            "final leaf d 2 vc 2 name d2d4\n",
            "backprop 0.00011706352233886719\n",
            "final leaf d 2 vc 2 name b2b4\n",
            "backprop 2.6702880859375e-05\n",
            "final leaf d 2 vc 2 name e1f2\n",
            "backprop 3.600120544433594e-05\n",
            "final leaf d 2 vc 2 name g2g3\n",
            "backprop 3.552436828613281e-05\n",
            "final leaf d 2 vc 2 name h2h3\n",
            "backprop 5.316734313964844e-05\n",
            "final leaf d 2 vc 2 name g1f3\n",
            "backprop 4.029273986816406e-05\n",
            "backprop 1.430511474609375e-06\n",
            "a7a6\n"
          ]
        }
      ],
      "source": [
        "moves = complete_game(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xp40kX7KG2i"
      },
      "outputs": [],
      "source": [
        "moves2 = moves.copy()\n",
        "board = chess.Board()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvx9zdd4KG2k"
      },
      "outputs": [],
      "source": [
        "board.push(moves2.pop(0))\n",
        "board"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
