{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcelloCeresini/ChessBreaker/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2iWAxgCHN7z"
      },
      "outputs": [],
      "source": [
        "username = 'MarcelloCeresini'\n",
        "repository = 'ChessBreaker'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG5cfeYvHhdU",
        "outputId": "15c7d15b-534b-4141-85c0-0e45928b136a"
      },
      "outputs": [],
      "source": [
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "    #%cd /content/drive/MyDrive/GitHub/\n",
        "    !git clone https://github.com/{username}/{repository}.git\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "    !pip3 install anytree\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qDwSWUnXcjn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import chess\n",
        "from anytree import Node\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from queue import Queue\n",
        "import ray\n",
        "\n",
        "ray.init()\n",
        "\n",
        "import utils\n",
        "from utils import plane_dict, Config, x_y_from_position\n",
        "from model import ResNet\n",
        "\n",
        "conf = Config()\n",
        "board = chess.Board()\n",
        "\n",
        "# legal_moves = board.legal_moves\n",
        "# for move in legal_moves:\n",
        "#     print(move.uci())  \n",
        "# print(legal_moves)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board = chess.Board()\n",
        "board.set_fen('rnbqkbnr/p1pppppp/8/1p6/4P3/8/PPPP1PPP/RNBQKBNR w KQkq')\n",
        "board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3TOlR3jMn4v"
      },
      "outputs": [],
      "source": [
        "def special_input_planes(board):                                    # not repeated planes\n",
        "    \n",
        "    special_planes = np.zeros([*conf.BOARD_SHAPE, conf.SPECIAL_PLANES], conf.PLANES_DTYPE_NP)\n",
        "    special_planes[:,:,0] = board.turn                                 \n",
        "    special_planes[:,:,1] = board.fullmove_number-1                    \n",
        "    special_planes[:,:,2] = board.has_kingside_castling_rights(True)   \n",
        "    special_planes[:,:,3] = board.has_queenside_castling_rights(True)  \n",
        "    special_planes[:,:,4] = board.has_kingside_castling_rights(False)  \n",
        "    special_planes[:,:,5] = board.has_queenside_castling_rights(False) \n",
        "    special_planes[:,:,6] = board.halfmove_clock                       \n",
        "    \n",
        "    # special_planes = np.stack([\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.turn                                 ), conf.PLANES_DTYPE_NP),   # whose turn it is\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.fullmove_number-1                    ), conf.PLANES_DTYPE_NP),   # don't know why but it starts from 1 on move 1, just reduce it by one and now it's right (MAX 255, using uint8!!)\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_kingside_castling_rights(True)   ), conf.PLANES_DTYPE_NP),   # True for White\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_queenside_castling_rights(True)  ), conf.PLANES_DTYPE_NP),\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_kingside_castling_rights(False)  ), conf.PLANES_DTYPE_NP),   # False for Black\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.has_queenside_castling_rights(False) ), conf.PLANES_DTYPE_NP),\n",
        "    #     np.full([*conf.BOARD_SHAPE], int(board.halfmove_clock                       ), conf.PLANES_DTYPE_NP)    # number of moves from last capture / pawn move --> reaching 50 means draw\n",
        "    # ])\n",
        "\n",
        "    return special_planes                                            # transpose to have plane number last --> in order to concat them\n",
        "\n",
        "\n",
        "# def update_planes(current, board, board_history):\n",
        "\n",
        "#     if current == None: # root, initialize to zero\n",
        "#         current = tf.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES], dtype=conf.PLANES_DTYPE)\n",
        "    \n",
        "#     planes = [] # since we cannot \"change\" a tensor after creating it, we create them one by one in a list and then stack them\n",
        "\n",
        "#     for color in range(2):                                                                                                  # for each color\n",
        "#         for piece_type in range(1, conf.N_PIECE_TYPES+1):                                                                   # for each piece type\n",
        "#             indices = []                                                                                                    # --> we save the position on the board in a list\n",
        "#             for position in list(board.pieces(piece_type, color)):                                                          # for each piece of that type\n",
        "#                 indices.append(x_y_from_position(position))                                                                 # the function transforms a number (1-64) into a tuple (1-8, 1-8)\n",
        "#             if len(indices) == 0:\n",
        "#                 tensor = uniform_tensor(tf.constant(0, dtype=conf.PLANES_DTYPE))\n",
        "#             else:\n",
        "#                 values = np.array([1]*len(indices), dtype=conf.PLANES_DTYPE_NP) # simply \"1\" in a list with unit8 dtype\n",
        "#                 tensor = tf.sparse.to_dense(tf.SparseTensor(dense_shape=[*conf.BOARD_SHAPE], indices=indices, values=values))   ### created as sparse because it's easier, needed as dense afterwards\n",
        "#             planes.append(tensor)\n",
        "#         planes.append(uniform_tensor(tf.constant(board_history.count(board_history[-1]), dtype=conf.PLANES_DTYPE)))         # adding a \"repetition plane\" for each color (simply count how many times the current (last) position has been encountered)\n",
        "\n",
        "#     # 1 stack\n",
        "#     current_planes = tf.transpose(tf.stack(planes), [1,2,0])    \n",
        "#     print(tf.shape(current_planes))                                                            # transpose them to have the planes as last dimension\n",
        "#     # 7 stacks (total 8 repetitions)\n",
        "#     old_planes = tf.slice(current, begin=[0,0,0], size=[*conf.BOARD_SHAPE, (conf.PAST_TIMESTEPS-1)*conf.REPEATED_PLANES])   # take the first 7 repetitions, slice them and paste them at the end of the new planes (last is discarded, as are special planes)\n",
        "    \n",
        "#     return tf.concat([current_planes, old_planes, special_input_planes(board)], axis=-1)    # also concat the special planes\n",
        "\n",
        "def update_planes(old, board, board_history):\n",
        "\n",
        "    if type(old) != np.ndarray: # root, initialize to zero\n",
        "        old = np.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES], dtype=conf.PLANES_DTYPE_NP)\n",
        "    \n",
        "    total_planes = np.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES], dtype=conf.PLANES_DTYPE_NP) # since we cannot \"change\" a tensor after creating it, we create them one by one in a list and then stack them\n",
        "    plane = -1\n",
        "    \n",
        "    repetition_counter = board_history.count(board_history[-1])\n",
        "    for color in range(2):                                                                                                  # for each color\n",
        "        for piece_type in range(1, conf.N_PIECE_TYPES+1):                                                                   # for each piece type\n",
        "            plane += 1\n",
        "            indices = map(x_y_from_position, list(board.pieces(piece_type, color)))        # for each piece of that type                                                                                            # --> we save the position on the board in a list\n",
        "            # the function transforms a number (1-64) into a tuple (1-8, 1-8)\n",
        "            for idx in indices:\n",
        "                total_planes[idx[0], idx[1], plane] = 1\n",
        "        plane += 1\n",
        "        total_planes[:, :, plane] = repetition_counter    # adding a \"repetition plane\" for each color (simply count how many times the current (last) position has been encountered)\n",
        "   \n",
        "    # 7 stacks (total 8 repetitions)\n",
        "    to_keep = tf.slice(old, begin=[0,0,0], size=[*conf.BOARD_SHAPE, (conf.PAST_TIMESTEPS-1)*conf.REPEATED_PLANES])   # take the first 7 repetitions, slice them and paste them at the end of the new planes (last is discarded, as are special planes)\n",
        "    \n",
        "    total_planes[:, :, conf.REPEATED_PLANES:(conf.REPEATED_PLANES+conf.OLD_PLANES_TO_KEEP)] = old[:, :, :conf.OLD_PLANES_TO_KEEP]\n",
        "    total_planes[:, :, conf.REPEATED_PLANES+conf.OLD_PLANES_TO_KEEP:] = special_input_planes(board)\n",
        "    \n",
        "    return total_planes\n",
        "\n",
        "\n",
        "#0.04062032699584961\n",
        "# 0.0007264614105224609\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv2zcMiUh9bU"
      },
      "outputs": [],
      "source": [
        "class MyNode(Node): # subclassing Node from Anytree to add some methods\n",
        "\n",
        "    def update_action_value(self, new_action_value):                                                        # used during backtracking to update action value if the simulation reached the end through that node\n",
        "        self.action_value += (new_action_value-self.action_value)/(self.visit_count+1)                      # simply the mean value, but computed iteratively\n",
        "\n",
        "    def calculate_upper_confidence_bound(self, num_total_iterations=1):                                     # Q + U --> U proportional to P/(1+N) --> parameter decides exploration vs. exploitation\n",
        "        new_UCF = self.action_value + conf.expl_param(num_total_iterations)*self.prior/(1+self.visit_count)\n",
        "        return new_UCF\n",
        "\n",
        "    def calculate_move_probability(self, num_total_iterations=1):                                           # N^(1/tau) --> tau is a temperature parameter (exploration vs. exploitation)\n",
        "        return self.visit_count**(1/conf.temp_param(num_total_iterations))\n",
        "\n",
        "@ray.remote\n",
        "def expand_node(root_node, full_moves, outcome, legal_moves):\n",
        "    # nodes_to_visit.put_nowait(root_node) ### remember\n",
        "                        \n",
        "    mask_idx = utils.mask_moves(legal_moves)\n",
        "    priors = [full_moves[idx[0], idx[1], idx[2]] for idx in mask_idx]                        # boolean mask returns a tensor of only the values that were masked (as a list let's say)\n",
        "    # 0.006434917449951172\n",
        "    # 1.3113021850585938e-05\n",
        "    root_node.action_value = outcome    \n",
        "\n",
        "    for move, prior in zip(legal_moves, priors):                                                # creating children\n",
        "        \n",
        "        root_board_fen = root_node.board.fen()\n",
        "        new_board = chess.Board()\n",
        "        new_board.set_fen(root_board_fen)\n",
        "        new_board.push(move)\n",
        "                                    \n",
        "        new_board_history = root_node.board_history.copy()                                      # and board history! (copy because list are pointers)\n",
        "        new_board_history.append(new_board.fen()[:-6])\n",
        "\n",
        "        planes = update_planes(root_node.planes, new_board, new_board_history)\n",
        "        \n",
        "        MyNode(\n",
        "            move.uci(), \n",
        "            parent = root_node,                                                                 # very important to build the tree\n",
        "            prior = prior,                                                                      # prior is the \"initial\" state_value of a node\n",
        "            visit_count = 0,                                                                    # initialize visit_count to 0\n",
        "            action_value = 0,\n",
        "            board = new_board, \n",
        "            board_history = new_board_history,                                                  \n",
        "            planes = planes             # update the planes --> each node stores its input planes!\n",
        "        )\n",
        "    \n",
        "    return root_node \n",
        "\n",
        "\n",
        "def MTCS(model, root_node, max_depth, num_restarts):\n",
        "    '''\n",
        "        As it is written, the search descends until it finds a leaf to be evalued, then restarts until it gathers a batch of evaluations\n",
        "        The descent, however, does not restart from the just evalued leafs, but always from the beginning (easier implementation)\n",
        "        This should IMPROVE exploration because the probability of entering a node is inversely proportional to the number of visits of that node\n",
        "    '''\n",
        "    evaluation_counter = 0\n",
        "    INIT_ROOT = root_node\n",
        "    nodes_to_visit = Queue()\n",
        "    # number of times to explore up until max_depth\n",
        "    i = 0\n",
        "\n",
        "    leaf_node_batch = []\n",
        "    legal_moves_batch = []\n",
        "    \n",
        "    while i < num_restarts:\n",
        "        if nodes_to_visit.empty():\n",
        "            root_node = INIT_ROOT\n",
        "            i+=1\n",
        "        else:\n",
        "            root_node = nodes_to_visit.get_nowait()\n",
        "        # print(i, root_node.name, root_node.depth, root_node.visit_count)\n",
        "        \n",
        "        while root_node.depth <= max_depth:  # while depth < max --> descend BUT STOP when you finished num_restarts AND the batch is empty AND you reach an already explored end of the tree with a subsequent descent\n",
        "            \n",
        "            # TODO: implement \"complete game\" inside MTCS --> stop the descent and give 1 as outcome (1/-1 depends)\n",
        "            \n",
        "            assert root_node.depth >= 0 and root_node.depth <= max_depth, \"depth is wrong\"          \n",
        "\n",
        "            if root_node.is_leaf:                                                                           # if it's leaf --> need to pass the position (planes) through the model, to get priors (action_values) and outcome (state_value)\n",
        "                if len(root_node.siblings) > 0:         # this part is to try and avoid batching the same node twice (so we evaluate a random sibling instead)\n",
        "                    leaf_node_name_list = [node.name for node in leaf_node_batch]\n",
        "                    if root_node.name in leaf_node_name_list:\n",
        "                        siblings_list = list(root_node.siblings)\n",
        "                        random_sibling = np.random.choice(siblings_list)\n",
        "                        while random_sibling.name in leaf_node_name_list and len(siblings_list)>1:\n",
        "                            siblings_list.remove(random_sibling) #do it with np.random in a range, and POP instead of remove\n",
        "                            random_sibling = np.random.choice(siblings_list)\n",
        "                        \n",
        "                        root_node = random_sibling\n",
        "                        \n",
        "                # important! save legal moves AFTER choosing root_node\n",
        "                legal_moves = list(root_node.board.legal_moves)\n",
        "                leaf_node_batch.append(root_node)\n",
        "                legal_moves_batch.append(legal_moves)\n",
        "                root_node.visit_count += 1\n",
        "\n",
        "                # print(\"to be evaluated\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "\n",
        "                if len(leaf_node_batch) == conf.BATCH_DIM or root_node == INIT_ROOT:\n",
        "\n",
        "\n",
        "                    plane_list = [root_node.planes for root_node in leaf_node_batch]\n",
        "                    # 0.0032072067260742188\n",
        "                    # 7.05718994140625e-05\n",
        "                    \n",
        "                    planes = np.stack(plane_list)\n",
        "\n",
        "                    full_moves_batch, outcome_batch = model(planes)\n",
        "                    evaluation_counter+=1\n",
        "\n",
        "                    full_moves_batch_np = full_moves_batch.numpy()\n",
        "                    outcome_batch_np = outcome_batch.numpy()\n",
        "\n",
        "                    def unstack(a, axis=0):\n",
        "                        return np.moveaxis(a, axis, 0)\n",
        "\n",
        "                    if np.shape(full_moves_batch_np)[0] != 1:\n",
        "                        full_moves_batch_np = unstack(full_moves_batch.numpy())\n",
        "                        outcome_batch_np = unstack(outcome_batch.numpy())\n",
        "\n",
        "                    #########################\n",
        "                    futures = [\n",
        "                        expand_node(root_node, full_moves, outcome, legal_moves)\n",
        "                        for root_node, full_moves, outcome, legal_moves \n",
        "                        in zip(leaf_node_batch, full_moves_batch_np, outcome_batch_np, legal_moves_batch)\n",
        "                    ]\n",
        "                    \n",
        "                    nodes_batch = ray.get(futures)\n",
        "                    [nodes_to_visit.put_nowait(node) for node in nodes_batch]\n",
        "                            \n",
        "                    leaf_node_batch = []\n",
        "                    legal_moves_batch = []\n",
        "                    break # restart another iteration\n",
        "\n",
        "                else:\n",
        "                    # after\n",
        "                    root_node = INIT_ROOT\n",
        "                    i += 1\n",
        "\n",
        "            else: # if it does not need to be evalued because it already has children \n",
        "                if root_node.depth < max_depth:                                                                 # if we are normally descending\n",
        "                    # print(\"choosing point\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                    children = root_node.children                                                               # get all the children (always != [])\n",
        "                    \n",
        "                    values = [child.calculate_upper_confidence_bound() for child in children]\n",
        "                    root_node = children[np.argmax(values)]\n",
        "                    root_node.visit_count += 1                                                                  # add 1 to the visit count of the chosen child\n",
        "                    # print(\"chosen node\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                else:\n",
        "                    # print(\"final leaf\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name, root_node.calculate_upper_confidence_bound())\n",
        "                    flag_max_depth = False\n",
        "                    outcome = root_node.action_value    # needed for when depth=max_depth AND NOT LEAF (that means, already visited leaf) --> don't REDO the evaluation, it would give the same result, simply copy it from before\n",
        "                    break                               # it will leave the while, max depth is reached\n",
        "           \n",
        "        # print(\"num_restarts\", i, \" - flag_r\", flag_restart, \" - flag_md\", flag_max_depth)\n",
        "        # barckpropagation of action value through the tree\n",
        "        # print(\"outcome\", outcome)\n",
        "        while root_node.depth > 0:\n",
        "            # root node should be an already evalued leaf, at max depth (so OUTCOME has been set)\n",
        "            assert root_node.depth > 0 and root_node.depth <= max_depth, \"depth is wrong\"\n",
        "            root_node = root_node.parent\n",
        "            root_node.update_action_value(outcome)\n",
        "\n",
        "    return INIT_ROOT, evaluation_counter\n",
        "\n",
        "\n",
        "def choose_move(root_node):\n",
        "    children = root_node.children\n",
        "    assert root_node.children != [], \"No children, cannot choose move\"\n",
        "    p = [child.calculate_move_probability() for child in children] \n",
        "    p_norm = [i/sum(p) for i in p] # normalize probabilities\n",
        "    root_node = np.random.choice(\n",
        "        children, \n",
        "        p = p_norm  # choose the child proportionally to the number of times it has been visited (exponentiated by a temperature parameter)\n",
        "    ) \n",
        "    root_node.parent = None # To detach the subtree and restart with the next move search\n",
        "\n",
        "    return root_node\n",
        "\n",
        "\n",
        "def complete_game(model, max_depth=7, num_restarts=100):\n",
        "    move_list = []\n",
        "    board = chess.Board()\n",
        "    board_history = [board.fen()[:-6]]                           # we remove the \"en passant\", \"halfmove clock\" and \"fullmove number\" from the fen --> position will be identical even if those values differ\n",
        "    root_node = MyNode(\n",
        "        \"Start\",                                                     # no name needed for initial position\n",
        "        board = board,\n",
        "        board_history = board_history,\n",
        "        planes = update_planes(None, board, board_history),    # start from empty planes and fill them (usually you need previous planes to fill them)\n",
        "        action_value=0,\n",
        "        visit_count=0\n",
        "        )\n",
        "\n",
        "    results = []\n",
        "    # while not root_node.board.is_game_over(claim_draw=True) and root_node.board.fullmove_number <= conf.MAX_MOVE_COUNT:\n",
        "    while not root_node.board.is_game_over(claim_draw=True):\n",
        "        tic = time()\n",
        "        root_node, eval_c = MTCS(model, root_node, max_depth = max_depth, num_restarts=num_restarts)                          # though the root node you can access all the tree\n",
        "        root_node = choose_move(root_node)\n",
        "        move_list.append(chess.Move.from_uci(root_node.name))\n",
        "        results.append((\n",
        "            int(root_node.planes[0,0,conf.REPEATED_PLANES+conf.OLD_PLANES_TO_KEEP+1]),  # it is the fullmove number\n",
        "            root_node.visit_count,\n",
        "            eval_c,\n",
        "            time()-tic,\n",
        "            root_node.action_value))\n",
        "\n",
        "    return move_list, root_node.board.outcome(claim_draw=True), results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNRD2BohKG2g",
        "outputId": "9c464466-c876-4ee8-de8f-4f18fee7f496"
      },
      "outputs": [],
      "source": [
        "model = ResNet()\n",
        "print(tf.shape(conf.DUMMY_INPUT))\n",
        "fm, ac = model(conf.DUMMY_INPUT)\n",
        "print(\"full moves shape\", fm.shape)\n",
        "print(\"action values shape\", ac.shape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "moves, outcome, results = complete_game(model, max_depth=3, num_restarts=15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "1pHHpicUKG2h",
        "outputId": "dfaf3585-f2a2-476d-8b67-9b364e1d3a38"
      },
      "outputs": [],
      "source": [
        "# res_dict = {}\n",
        "# games = []\n",
        "# outcomes = []\n",
        "# for depth in [4, 6, 8, 10]:\n",
        "#     for n_rep in [100, 1000, 10000]:\n",
        "#         tic = time()\n",
        "#         moves, outcome, results = complete_game(model, max_depth=depth, num_restarts=n_rep)\n",
        "#         res_dict[(depth, n_rep, \"eval\")] = np.average([res[2] for res in results])\n",
        "#         res_dict[(depth, n_rep, \"time\")] = np.average([res[3] for res in results])\n",
        "#         games.append(moves)\n",
        "#         outcomes.append(outcome)\n",
        "#         print(depth, n_rep, time()-tic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xp40kX7KG2i"
      },
      "outputs": [],
      "source": [
        "# moves2 = moves.copy()\n",
        "# board = chess.Board()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(280):\n",
        "#     board.push(moves2.pop(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# board.push(moves2.pop(0))\n",
        "# board"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "6ff546d1c5a7064c8e32c19edaef78491647a0db70d1b75d69edec23d383707d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
