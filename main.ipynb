{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j2iWAxgCHN7z"
      },
      "outputs": [],
      "source": [
        "username = 'MarcelloCeresini'\n",
        "repository = 'ChessBreaker'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG5cfeYvHhdU",
        "outputId": "83f1d0f6-6925-4b26-a582-8485ff66edde"
      },
      "outputs": [],
      "source": [
        "# COLAB ONLY CELLS\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !nvidia-smi             # Check which GPU has been chosen for us\n",
        "    !rm -rf logs\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "    #%cd /content/drive/MyDrive/GitHub/\n",
        "    !git clone https://github.com/{username}/{repository}.git\n",
        "    %cd {repository}\n",
        "    %ls\n",
        "    !pip3 install anytree\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5qDwSWUnXcjn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-01 22:54:18.949995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:18.976328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:18.976522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:18.977288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-08-01 22:54:18.978392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:18.978566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:18.978684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:19.392094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:19.392263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:19.392385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-01 22:54:19.392500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3381 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import chess\n",
        "from anytree import Node\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from queue import Queue\n",
        "from collections import deque\n",
        "import ray\n",
        "\n",
        "ray.shutdown()\n",
        "ray.init(\n",
        "    num_cpus=1,\n",
        "    num_gpus=0,\n",
        "    include_dashboard=False)\n",
        "\n",
        "\n",
        "from numpy.random import default_rng\n",
        "rng = default_rng()\n",
        "\n",
        "import utils\n",
        "from utils import plane_dict, Config, x_y_from_position\n",
        "from model import create_model_v2\n",
        "\n",
        "conf = Config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yv2zcMiUh9bU"
      },
      "outputs": [],
      "source": [
        "class MyNode(Node): # subclassing Node from Anytree to add some methods\n",
        "\n",
        "    def update_action_value(self, new_action_value):                                                        # used during backtracking to update action value if the simulation reached the end through that node\n",
        "        self.action_value += (new_action_value-self.action_value)/(self.visit_count+1)                      # simply the mean value, but computed iteratively\n",
        "\n",
        "    def calculate_upper_confidence_bound(self, num_total_iterations=1):                                     # Q + U --> U proportional to P/(1+N) --> parameter decides exploration vs. exploitation\n",
        "        new_UCF = self.action_value + conf.expl_param(num_total_iterations)*self.prior/(1+self.visit_count)\n",
        "        return new_UCF\n",
        "\n",
        "    def calculate_move_probability(self, num_move=1):                                           # N^(1/tau) --> tau is a temperature parameter (exploration vs. exploitation)\n",
        "        return self.visit_count**(1/conf.temp_param(num_move))\n",
        "\n",
        "\n",
        "def MTCS(model, root_node, max_depth, num_restarts):\n",
        "    '''\n",
        "        The search descends until it finds a leaf to be evalued, then restarts until it gathers a batch of evaluations, then expands all the nodes in the batch\n",
        "        If the maximum depth is reached, the algorithm then backpropagates the action value of the reached node back to the root of the tree\n",
        "        Exploration incentivised by the decrease of action value / upper confidence bound with each visit to the node\n",
        "        Exploitation incentivised by the two parameters temp_param and expl_param (respectively to choose almost surely the most probable move, and to focus more on the action value rather than the prior of the node)\n",
        "    '''\n",
        "    evaluation_counter = 0\n",
        "    INIT_ROOT = root_node\n",
        "    nodes_to_visit = Queue()\n",
        "    # number of times to explore up until max_depth\n",
        "    i = 0\n",
        "\n",
        "    leaf_node_batch = []\n",
        "    legal_moves_batch = []\n",
        "    \n",
        "    while i < num_restarts:\n",
        "        if nodes_to_visit.empty():\n",
        "            root_node = INIT_ROOT\n",
        "            i+=1\n",
        "        else:\n",
        "            root_node = nodes_to_visit.get_nowait()\n",
        "        # print(i, root_node.name, root_node.depth, root_node.visit_count)\n",
        "        \n",
        "        step_down = True\n",
        "        control_counter = 0\n",
        "        while step_down:\n",
        "            control_counter+=1\n",
        "            if control_counter > 2*max_depth: \n",
        "                print(\"stuck in loop, leaving\")\n",
        "                break # bigger margin, but if it is stuk in a loop for some reason, at least it leaves\n",
        "            \n",
        "            # assert root_node.depth >= 0 and root_node.depth <= max_depth, \"depth is wrong\"\n",
        "            if root_node.is_leaf and not root_node.is_finish_position:                                                                           # if it's leaf --> need to pass the position (planes) through the model, to get priors (action_values) and outcome (state_value)\n",
        "                step_down = False\n",
        "\n",
        "                if len(root_node.siblings) > 0:         # this part is to try and avoid batching the same node twice (so we evaluate a random sibling instead)\n",
        "                    leaf_node_list = [node.board_history for node in leaf_node_batch]\n",
        "                    if root_node.board_history in leaf_node_list:\n",
        "                        siblings_list = list(root_node.siblings)\n",
        "                        random_sibling = np.random.choice(siblings_list)\n",
        "                        while random_sibling.board_history in leaf_node_list and len(siblings_list)>1:\n",
        "                            siblings_list.remove(random_sibling) #do it with np.random in a range, and POP instead of remove\n",
        "                            random_sibling = np.random.choice(siblings_list)\n",
        "                        \n",
        "                        root_node = random_sibling\n",
        "                        \n",
        "                # important! save legal moves AFTER choosing root_node\n",
        "                legal_moves = list(root_node.board.legal_moves)\n",
        "\n",
        "                if len(legal_moves) == 0:\n",
        "                    step_down = False\n",
        "                    final_outcome = root_node.board.outcome(claim_draw=True)\n",
        "\n",
        "                    if final_outcome != None:\n",
        "                        root_node.is_finish_position = True\n",
        "                        if final_outcome.winner == None:\n",
        "                            root_node.action_value = 0\n",
        "                        else:\n",
        "                            root_node.action_value = int(final_outcome.winner)*2-1\n",
        "                    else:\n",
        "                        print(\"Something's wrong\")\n",
        "                else:\n",
        "                    leaf_node_batch.append(root_node)\n",
        "                    legal_moves_batch.append(legal_moves)\n",
        "                \n",
        "                root_node.visit_count += 1\n",
        "\n",
        "                # print(\"to be evaluated\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "\n",
        "                if len(leaf_node_batch) == conf.BATCH_DIM or root_node == INIT_ROOT:\n",
        "                    # in order to avoid creating multiple times the children of the same node, we only keep unique values\n",
        "                    if len(set(leaf_node_batch)) < conf.BATCH_DIM:\n",
        "                        leaf_node_batch, legal_moves_batch = utils.reduce_repetitions(leaf_node_batch, legal_moves_batch)                    \n",
        "                    \n",
        "                    plane_list = [root_node.planes for root_node in leaf_node_batch]\n",
        "                    # 0.0032072067260742188\n",
        "                    # 7.05718994140625e-05\n",
        "                    \n",
        "                    planes = np.stack(plane_list)\n",
        "\n",
        "                    full_moves_batch, outcome_batch = model(planes)\n",
        "                    evaluation_counter+=1\n",
        "\n",
        "                    full_moves_batch_np = full_moves_batch.numpy()\n",
        "                    # print(np.shape(full_moves_batch_np[0]))\n",
        "                    outcome_batch_np = outcome_batch.numpy()\n",
        "\n",
        "                    if np.shape(full_moves_batch_np)[0] != 1:\n",
        "                        full_moves_batch_np = np.moveaxis(full_moves_batch.numpy(), 0, 0)\n",
        "                        outcome_batch_np = np.moveaxis(outcome_batch.numpy(), 0, 0)\n",
        "                    \n",
        "                    for root_node, full_moves, outcome, legal_moves in zip(leaf_node_batch, full_moves_batch_np, outcome_batch_np, legal_moves_batch):\n",
        "                        nodes_to_visit.put_nowait(root_node)\n",
        "                        \n",
        "                        mask_idx = utils.mask_moves_flatten(legal_moves)\n",
        "                        priors = [full_moves[idx] for idx in mask_idx]                        # boolean mask returns a tensor of only the values that were masked (as a list let's say)\n",
        "                        # 0.006434917449951172\n",
        "                        # 1.3113021850585938e-05\n",
        "                        root_node.action_value = outcome    \n",
        "                        \n",
        "                        if root_node == INIT_ROOT:  # increase exploration at the root, since if the network is not good it will not make good starting choices\n",
        "                            dir_noise = rng.dirichlet([conf.ALPHA_DIRICHLET]*len(priors))\n",
        "                            priors = [((1-conf.EPS_NOISE)*p + conf.EPS_NOISE*noise) for p, noise in zip(priors, dir_noise)]\n",
        "\n",
        "                        for move, prior in zip(legal_moves, priors):                                                # creating children\n",
        "\n",
        "                            root_board_fen = root_node.board.fen()\n",
        "                            new_board = chess.Board()\n",
        "                            new_board.set_fen(root_board_fen)\n",
        "                            new_board.push(move)\n",
        "                                                        \n",
        "                            new_board_history = root_node.board_history.copy()                                      # and board history! (copy because list are pointers)\n",
        "                            new_board_history.append(new_board.fen()[:-6])\n",
        "\n",
        "                            planes = utils.update_planes(root_node.planes, new_board, new_board_history)\n",
        "                            \n",
        "                            MyNode(\n",
        "                                move.uci(), \n",
        "                                parent = root_node,                                                                 # very important to build the tree\n",
        "                                prior = prior,                                                                      # prior is the \"initial\" state_value of a node\n",
        "                                visit_count = 0,                                                                    # initialize visit_count to 0\n",
        "                                action_value = 0,\n",
        "                                is_finish_position = False,\n",
        "                                board = new_board, \n",
        "                                board_history = new_board_history,                                                  \n",
        "                                planes = planes             # update the planes --> each node stores its input planes!\n",
        "                            )\n",
        "\n",
        "                    leaf_node_batch = []\n",
        "                    legal_moves_batch = []\n",
        "\n",
        "            else: # if it does not need to be evalued because it already has children \n",
        "                if root_node.depth < max_depth and not root_node.is_finish_position:                                # if we are normally descending\n",
        "                    # print(\"choosing point\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                    children = root_node.children                                                               # get all the children (always != [])\n",
        "                    \n",
        "                    values = [child.calculate_upper_confidence_bound() for child in children]\n",
        "                    root_node = children[np.argmax(values)]\n",
        "                    root_node.visit_count += 1                                                                  # add 1 to the visit count of the chosen child\n",
        "                    # print(\"chosen node\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name)\n",
        "                else:\n",
        "                    step_down = False                                # it will leave the while, max depth is reached\n",
        "                    # print(\"final leaf\", \"d\", root_node.depth, \"vc\", root_node.visit_count, \"name\", root_node.name, root_node.calculate_upper_confidence_bound())\n",
        "                    outcome = root_node.action_value    # needed for when depth=max_depth AND NOT LEAF (that means, already visited leaf) --> don't REDO the evaluation, it would give the same result, simply copy it from before\n",
        "                    # barckpropagation of action value through the tree\n",
        "                    while root_node.depth > 0:\n",
        "                        # root node should be an already evalued leaf, at max depth (so OUTCOME has been set)\n",
        "                        # assert root_node.depth > 0 and root_node.depth <= max_depth, \"depth is wrong\"\n",
        "                        root_node = root_node.parent\n",
        "                        root_node.update_action_value(outcome)\n",
        "\n",
        "    return INIT_ROOT, evaluation_counter\n",
        "\n",
        "\n",
        "def choose_move(root_node, num_move):\n",
        "    # add dirichlet noise to the root node? (page 14, Mastering Chess and Shogi by self play... --> configuration)\n",
        "    children = root_node.children\n",
        "    assert root_node.children != [], \"No children, cannot choose move\"\n",
        "    p = [child.calculate_move_probability(num_move) for child in children] \n",
        "    p_norm = [i/sum(p) for i in p] # normalize probabilities\n",
        "\n",
        "    root_node = np.random.choice(\n",
        "        children, \n",
        "        p = p_norm  # choose the child proportionally to the number of times it has been visited (exponentiated by a temperature parameter)\n",
        "    ) \n",
        "    root_node.parent = None # To detach the subtree and restart with the next move search\n",
        "\n",
        "    return root_node\n",
        "\n",
        "\n",
        "@ray.remote\n",
        "def complete_game(model, starting_fen=None, max_depth=conf.MAX_DEPTH, num_restarts=conf.NUM_RESTARTS):\n",
        "    debugging = False\n",
        "    board = chess.Board()\n",
        "    if starting_fen != None:\n",
        "        board.set_fen(starting_fen)\n",
        "    board_history = [board.fen()[:-6]]                           # we remove the \"en passant\", \"halfmove clock\" and \"fullmove number\" from the fen --> position will be identical even if those values differ\n",
        "    \n",
        "    root_node = MyNode(\n",
        "        \"Start\",                                                     # no name needed for initial position\n",
        "        board = board,\n",
        "        board_history = board_history,\n",
        "        planes = utils.update_planes(None, board, board_history),    # start from empty planes and fill them (usually you need previous planes to fill them)\n",
        "        action_value=0,\n",
        "        visit_count=0,\n",
        "        is_finish_position = False\n",
        "        )\n",
        "\n",
        "    if debugging:\n",
        "        move_list = []\n",
        "        results = []\n",
        "    \n",
        "    match_planes = []\n",
        "    match_policy = []\n",
        "    move_counter = 0\n",
        "\n",
        "    # while not root_node.board.is_game_over(claim_draw=True) and root_node.board.fullmove_number <= conf.MAX_MOVE_COUNT:\n",
        "    while not root_node.board.is_game_over(claim_draw=True) and move_counter < conf.MAX_MOVE_COUNT:\n",
        "        move_counter += 1\n",
        "        if move_counter % 50 == 0:\n",
        "            print(move_counter)\n",
        "        tic = time()\n",
        "        root_node, eval_c = MTCS(model, root_node, max_depth = max_depth, num_restarts=num_restarts)                            # though the root node you can access all the tree\n",
        "\n",
        "        match_planes.append(root_node.planes)                                                                                   # 8x8x113\n",
        "        root_node = choose_move(root_node, num_move=move_counter)                                                                                      \n",
        "        match_policy.append(utils.mask_moves_flatten([chess.Move.from_uci(root_node.name)])[0])                                         # appends JUST AN INDEX\n",
        "\n",
        "        if debugging:\n",
        "            ###### only for debugging ######\n",
        "            move_list.append(chess.Move.from_uci(root_node.name))\n",
        "            results.append((\n",
        "                int(root_node.planes[0,0,conf.REPEATED_PLANES+conf.OLD_PLANES_TO_KEEP+1]),  # it is the fullmove number\n",
        "                root_node.visit_count,\n",
        "                eval_c,\n",
        "                time()-tic,\n",
        "                root_node.action_value))\n",
        "            \n",
        "            print(move_counter, time()-tic)\n",
        "            ################################\n",
        "\n",
        "    if move_counter >= conf.MAX_MOVE_COUNT:\n",
        "        outcome = utils.outcome(\"1/2-1/2\")\n",
        "    else:\n",
        "        outcome = utils.outcome(root_node.board.outcome(claim_draw=True).result())\n",
        "\n",
        "    # TODO: try if \"match_policy\" is a problem, because it's a list\n",
        "    if debugging:\n",
        "        return move_list, outcome, results, match_planes, match_policy                             # only needed for the program are the match_planes (input for learning) and the outcome/match_policy (loss)\n",
        "    \n",
        "    return match_planes, match_policy, outcome\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uNRD2BohKG2g"
      },
      "outputs": [],
      "source": [
        "# model = ResNet()\n",
        "# DUMMY_INPUT = tf.stack([tf.zeros([*conf.BOARD_SHAPE, conf.TOTAL_PLANES])]*8, axis = 0)\n",
        "# print(tf.shape(DUMMY_INPUT))\n",
        "# fm, ac = model(DUMMY_INPUT)\n",
        "# print(\"full moves shape\", fm.shape)\n",
        "# print(\"action values shape\", ac.shape)\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1pHHpicUKG2h"
      },
      "outputs": [],
      "source": [
        "# model = create_model_v2()\n",
        "# res_dict = {}\n",
        "# games = []\n",
        "# outcomes = []\n",
        "# for depth in [8, 6, 4, 2]:\n",
        "#     for n_rep in [100, 80, 60, 40, 30, 20, 10, 5]:\n",
        "#         tic = time()\n",
        "#         moves, outcome, results, _, _ = complete_game(model, max_depth=depth, num_restarts=n_rep)\n",
        "#         res_dict[(depth, n_rep, \"eval\")] = np.average([res[2] for res in results])\n",
        "#         res_dict[(depth, n_rep, \"time\")] = np.average([res[3] for res in results])\n",
        "#         games.append(moves)\n",
        "#         outcomes.append(outcome)\n",
        "#         print(depth, \"\\t\", n_rep, \"\\t\", time()-tic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8vRhjzdqR-4e",
        "outputId": "8a2c0e07-4371-4528-d02d-01fe8d012679"
      },
      "outputs": [],
      "source": [
        "# reps = [5, 10, 20, 30, 40, 60, 80, 100]\n",
        "# depths = [2, 4, 6, 8]\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "# [plt.scatter(reps, [res_dict[(depth, rep, \"eval\")] for rep in reps]) for depth in depths]\n",
        "\n",
        "# plt.legend(depths)\n",
        "# plt.title(\"Evaluations vs. repetitions\")\n",
        "# plt.xlabel(\"Repetitions\")\n",
        "# plt.ylabel(\"Total evaluations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k1HAFM0ZR-4f",
        "outputId": "1a7569a8-90bb-4bc1-e0a9-7ac7cdd1fae1"
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "# [plt.scatter(reps, [res_dict[(depth, rep, \"time\")] for rep in reps]) for depth in depths]\n",
        "# # plt.scatter(reps, times)\n",
        "\n",
        "# plt.legend(depths)\n",
        "# plt.title(\"Time vs. repetitions\")\n",
        "# plt.xlabel(\"Repetitions\")\n",
        "# plt.ylabel(\"Mean time per move\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Vg2o4fMGR-4h"
      },
      "outputs": [],
      "source": [
        "# import json, codecs\n",
        "\n",
        "# Zl = [[res_dict[(depth, rep, \"time\")] for rep in reps] for depth in depths]\n",
        "\n",
        "# X, Y = np.meshgrid(reps, depths)\n",
        "# # Z_time = np.stack([\n",
        "# #     times\n",
        "# # ])\n",
        "\n",
        "\n",
        "# Xl = X.tolist() # nested lists with same data, indices\n",
        "# Yl = Y.tolist() # nested lists with same data, indices\n",
        "# # Zl = Z_time.tolist() # nested lists with same data, indices\n",
        "\n",
        "# file_path_X = \"data/chartX.json\" ## your path variable\n",
        "# file_path_Y = \"data/chartY.json\" ## your path variable\n",
        "# file_path_Z = \"data/chartZ.json\" ## your path variable\n",
        "\n",
        "# json.dump(Xl, codecs.open(file_path_X, 'w', encoding='utf-8'), \n",
        "#           separators=(',', ':'), \n",
        "#           sort_keys=True, \n",
        "#           indent=4) ### this saves the array in .json format\n",
        "\n",
        "# json.dump(Yl, codecs.open(file_path_Y, 'w', encoding='utf-8'), \n",
        "#           separators=(',', ':'), \n",
        "#           sort_keys=True, \n",
        "#           indent=4) ### this saves the array in .json format\n",
        "\n",
        "# json.dump(Zl, codecs.open(file_path_Z, 'w', encoding='utf-8'), \n",
        "#           separators=(',', ':'), \n",
        "#           sort_keys=True, \n",
        "#           indent=4) ### this saves the array in .json format\n",
        "\n",
        "# # fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
        "# # surf = ax.plot_surface(X, Y, Z_time, linewidth=0, antialiased=False)\n",
        "\n",
        "# # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "fixed_model = create_model_v2()\n",
        "# fixed_model.save(conf.PATH_FIXED_MODEL)\n",
        "\n",
        "# updating_model = create_model_v2()\n",
        "# updating_model.save(conf.PATH_UPDATING_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I4OzNXseR-4k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://84bac820-093b-45a1-9546-53440f166681/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://84bac820-093b-45a1-9546-53440f166681/assets\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m 2022-08-01 22:54:29.490433: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m 2022-08-01 22:54:29.490501: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Franco4\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m 2022-08-01 22:54:29.490513: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Franco4\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m 2022-08-01 22:54:29.490665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.47.3\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m 2022-08-01 22:54:29.490700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.47.3\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m 2022-08-01 22:54:29.490709: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.47.3\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m 2022-08-01 22:54:29.491038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "\u001b[2m\u001b[36m(pid=266626)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266626)\u001b[0m inside\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266626)\u001b[0m /home/marcello/github/ChessBreaker/env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\u001b[2m\u001b[36m(complete_game pid=266626)\u001b[0m   result = getattr(asarray(obj), method)(*args, **kwds)\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://4a0d34a6-ea69-440f-aceb-7ebf64fb2ceb/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://4a0d34a6-ea69-440f-aceb-7ebf64fb2ceb/assets\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m 2022-08-01 22:54:38.648541: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m 2022-08-01 22:54:38.648629: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Franco4\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m 2022-08-01 22:54:38.648639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Franco4\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m 2022-08-01 22:54:38.648774: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.47.3\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m 2022-08-01 22:54:38.648823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.47.3\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m 2022-08-01 22:54:38.648832: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.47.3\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m 2022-08-01 22:54:38.649169: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "\u001b[2m\u001b[36m(pid=266622)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266622)\u001b[0m inside\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266622)\u001b[0m /home/marcello/github/ChessBreaker/env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\u001b[2m\u001b[36m(complete_game pid=266622)\u001b[0m   result = getattr(asarray(obj), method)(*args, **kwds)\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266626)\u001b[0m outside\n",
            "INFO:tensorflow:Assets written to: ram://a96c5c83-8d97-4145-9f4d-f4f85c25c5c8/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://a96c5c83-8d97-4145-9f4d-f4f85c25c5c8/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266622)\u001b[0m outside\n",
            "\u001b[2m\u001b[36m(complete_game pid=266626)\u001b[0m inside\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://17e8af99-fb59-4cd4-bd02-2c557a3502af/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://17e8af99-fb59-4cd4-bd02-2c557a3502af/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266622)\u001b[0m inside\n",
            "\u001b[2m\u001b[36m(complete_game pid=266626)\u001b[0m outside\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://c2d86658-85d6-44d4-b635-1ddbf990d71b/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ram://c2d86658-85d6-44d4-b635-1ddbf990d71b/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(complete_game pid=266626)\u001b[0m inside\n",
            "\u001b[2m\u001b[36m(complete_game pid=266622)\u001b[0m outside\n",
            "25\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([array([[[0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.]],\n",
              "  \n",
              "         [[0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.]],\n",
              "  \n",
              "         [[0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 1., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.]],\n",
              "  \n",
              "         [[0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.]],\n",
              "  \n",
              "         [[0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          ...,\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.],\n",
              "          [0., 0., 0., ..., 0., 0., 3.]]], dtype=float16)],\n",
              " [3876.0],\n",
              " [0.0])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = tf.data.TextLineDataset(conf.PATH_ENDGAME_TRAIN_DATASET).shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# using np.arrays because we add chunks of data and not one at a time (O(n) to move all data is actually O(n/m), with m chunk size)\n",
        "# and also we need to sample randomly batches of data, that for linked lists (like queue) is O(n*batch_zize), instead for arrays is O(batch_size)\n",
        "\n",
        "exp_buffer = utils.ExperienceBuffer(conf.MAX_BUFFER_SIZE)\n",
        "\n",
        "# start_learning_from = 50000 # number of MOVES\n",
        "\n",
        "# idea: start learning after 50000 samples are in the queue, and randomly select them to pass them through the network, then REMOVE them from the queue\n",
        "# IN PARALLEL, keep playing games with the fixed_model to fill up the queue --> if this step is much faster (or the opposite) --> just wait a bit for the slower one, so that the queue always stays\n",
        "# between ~50k and ~100k\n",
        "\n",
        "# ideally: infinite while loop that launches in parallel two threads/processes:\n",
        "# 1) generates self-play samples (planes, (moves, outcome)) that then get COPIED (otherwise parallelism will screw everything up) and added to the queue\n",
        "# 2) randomly selects batches of 512 samples from the buffer\n",
        "\n",
        "@tf.function\n",
        "def gradient_application(x, y_policy, y_value, model, optimizer, metric):\n",
        "    with tf.GradientTape() as tape:\n",
        "        policy_logits, value_logits = model(x)\n",
        "        policy_loss_value = utils.loss_policy(y_policy, policy_logits)\n",
        "        value_loss_value = utils.loss_value(y_value, value_logits)\n",
        "        loss = policy_loss_value + value_loss_value + sum(model.losses) # to add regularization loss\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    metric.update_state(y_policy, policy_logits)\n",
        "\n",
        "    return policy_loss_value, value_loss_value, loss\n",
        "\n",
        "\n",
        "def train_step(model, optimizer, metric, steps, steps_from_last_stats_print):\n",
        "    tic = time()\n",
        "    total_loss = 0\n",
        "\n",
        "    planes_batch, moves_batch, outcome_batch = exp_buffer.sample(conf.SELF_PLAY_BATCH)\n",
        "        \n",
        "    policy_loss_value, value_loss_value, loss = gradient_application(planes_batch, moves_batch, outcome_batch, model, optimizer, metric)\n",
        "\n",
        "    if steps_from_last_stats_print > conf.STEPS_PER_UPDATE:\n",
        "        steps_from_last_stats_print = 0\n",
        "\n",
        "        to_print = [\"step: \", steps]\n",
        "        to_print.append(\"- policy loss (instantaneous): \")\n",
        "        to_print.append(policy_loss_value)\n",
        "        to_print.append(\"- value_loss (instantaneous): \")\n",
        "        to_print.append(value_loss_value)\n",
        "        to_print.append(\"- loss (instantaneous): \")\n",
        "        to_print.append(loss)\n",
        "        to_print.append(\"- policy accuracy: \")\n",
        "        to_print.append(metric.result())\n",
        "        print(to_print)\n",
        "\n",
        "        metric.reset_states()\n",
        "\n",
        "    total_loss += loss\n",
        "\n",
        "    print(time()-tic)\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def train_loop(fixed_model):\n",
        "    steps = 0\n",
        "    filled_up = 0\n",
        "    steps_from_last_model_update = 0\n",
        "    steps_from_last_eval = 0\n",
        "    steps_from_last_stats_print = 0\n",
        "\n",
        "    # fixed_model = tf.keras.models.load_model(conf.PATH_FIXED_MODEL)\n",
        "    # updating_model = tf.keras.models.load_model(conf.PATH_UPDATING_MODEL)\n",
        "\n",
        "    # tb_callback = tf.keras.callbacks.TensorBoard(\n",
        "    #     log_dir = \"logs/self-play\", \n",
        "    #     write_graph = False,\n",
        "    #     write_steps_per_second = True,\n",
        "    #     update_freq = conf.STEPS_PER_UPDATE\n",
        "    # )\n",
        "    # tb_callback.set_model(updating_model)\n",
        "\n",
        "\n",
        "    ##### ALREADY COMPILED MODEL, DO WE NEED THIS?\n",
        "    # lr_boundaries = [100000, 300000, 500000]    # from paper\n",
        "    # lr_values = [0.2, 0.02, 0.002, 0.0002]      # from paper\n",
        "    # lr_scheduler = tf.keras.optimizers.schedules.PiecewiseConstantDecay(lr_boundaries, lr_values)\n",
        "    # optimizer = tf.keras.optimizers.Adam(learning_rate = lr_scheduler)\n",
        "\n",
        "    # loss_policy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # from paper\n",
        "    # loss_value = tf.keras.losses.MeanSquaredError()                     # from paper\n",
        "\n",
        "    # metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    tot_moves = 0\n",
        "    tot_games = 0\n",
        "\n",
        "    while steps < conf.TOTAL_STEPS:\n",
        "\n",
        "        starting_positions = list(dataset.take(5))\n",
        "        \n",
        "        game_ids = []\n",
        "\n",
        "        for position in starting_positions:\n",
        "            game_ids.append(\n",
        "                complete_game.remote(\n",
        "                    fixed_model, \n",
        "                    starting_fen=position.numpy().decode(\"utf8\"), \n",
        "                    max_depth=conf.MAX_DEPTH, \n",
        "                    num_restarts=conf.NUM_RESTARTS\n",
        "                )\n",
        "            )\n",
        "\n",
        "        for id_ in game_ids:\n",
        "            result = ray.get(id_)\n",
        "            exp_buffer.push(result)\n",
        "        break\n",
        "\n",
        "        n_moves, filled_up = (fixed_model, conf.NUM_PARALLEL_GAMES, filled_up)\n",
        "        \n",
        "        tot_moves += n_moves\n",
        "        tot_games += conf.NUM_PARALLEL_GAMES\n",
        "        mean_length_game = tot_moves/tot_games\n",
        "\n",
        "        for i in conf.NUM_TRAINING_STEPS:\n",
        "            cycle_loss, cycle_steps = train_step(updating_model, exp_buffer.filled_up, conf.OPTIMIZER, conf.LOSS_FN_POLICY, conf.LOSS_FN_VALUE, conf.METRIC_FN_POLICY, steps, steps_from_last_stats_print)\n",
        "\n",
        "        if steps_from_last_model_update > conf.STEPS_PER_UPDATE:\n",
        "            steps_from_last_model_update = 0\n",
        "\n",
        "            updating_model.save(conf.PATH_UPDATING_MODEL, save_traces=False) # should decrease saving time, since we don't have custome layers/models\n",
        "            fixed_model = tf.keras.models.load_model(conf.PATH_UPDATING_MODEL)\n",
        "        \n",
        "        if steps_from_last_eval > conf.STEPS_PER_EVAL_CKPT == 0:\n",
        "            steps_from_last_eval = 0\n",
        "\n",
        "            updating_model.save(conf.PATH_CKPT_FOR_EVAL.format(steps), save_traces=False)\n",
        "\n",
        "        steps += conf.NUM_TRAINING_STEPS\n",
        "        steps_from_last_model_update += conf.NUM_TRAINING_STEPS\n",
        "        steps_from_last_eval += conf.NUM_TRAINING_STEPS\n",
        "        steps_from_last_stats_print += conf.NUM_TRAINING_STEPS\n",
        "\n",
        "train_loop(fixed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFUrtHf_Pg9B",
        "outputId": "4600f6b1-9c82-43e1-d4a9-140661159ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]], shape=(8, 4672), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "qty = 10000\n",
        "\n",
        "# labels = np.zeros((qty,3))\n",
        "# labels[:, 0] = 45\n",
        "# labels[:, 1] = 1\n",
        "# labels[:, 2] = 300\n",
        "\n",
        "# predictions = np.random.rand(qty, 8, 8, 73)\n",
        "# print(labels.shape)\n",
        "# print(predictions.shape)\n",
        "# # bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "# # bce(labels, predictions).numpy()\n",
        "\n",
        "# cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# cce(labels, predictions).numpy()\n",
        "\n",
        "x = np.zeros((8, 8, 8, 73))\n",
        "x[0, 2, 3, 5] = 1\n",
        "# x= np.array(x)\n",
        "\n",
        "\n",
        "lay = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "print(lay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hT4ZN_PQOro",
        "outputId": "0291c026-7c08-4b12-ede0-67468fd7d5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "index 1392\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "arr_x = 2\n",
        "arr_y = 3\n",
        "arr_z = 5\n",
        "\n",
        "print(x[0, arr_x, arr_y, arr_z])\n",
        "idx = np.ravel_multi_index([arr_x, arr_y, arr_z], np.shape(x)[1:])\n",
        "print(\"index\", idx)\n",
        "print(lay[0][idx].numpy() == x[0, arr_x, arr_y, arr_z])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "6ff546d1c5a7064c8e32c19edaef78491647a0db70d1b75d69edec23d383707d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
